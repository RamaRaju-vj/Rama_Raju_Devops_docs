{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p>Note</p> <p>This documentation is work in progress!!!</p> <p>Tip</p>"},{"location":"#recommended-chrome-extensions-for-summarizing","title":"\ud83d\udd0d Recommended Chrome Extensions for Summarizing","text":"<p>Please use the following Chrome extensions if you want a summarized version of each topic:</p> <ul> <li>Condense \u2013 Summarize &amp; Chat  (Not sponsored)</li> <li>Storytell \u2013 AI Summarizer (Not sponsored)</li> </ul> <p>Note: First navigate to the topic you need, and then use the extension for the summary.</p>"},{"location":"#folder-descriptions","title":"\ud83d\udccc Folder Descriptions","text":"<pre><code>\ud83d\udcc2 docs/\n\u2502  \n\u251c\u2500\u2500 \ud83d\ude80  Ram Portfolio          \u2192 Personal Web Portfolio\n\u2502  \n\u251c\u2500\u2500 \u2638\ufe0f  Kubernetes/            \u2192 Kubernetes configurations, deployments, and best practices.\n\u2502  \n\u251c\u2500\u2500 \u2699\ufe0f  CI-CD                  \u2192 Continuous Integration and Deployment practices.\n\u2502  \n\u251c\u2500\u2500 \ud83c\udf10  Networking             \u2192 Network protocols, cloud networking, and security.\n\u2502  \n\u251c\u2500\u2500 \ud83c\udfd7\ufe0f  Terraform              \u2192 Infrastructure as Code (IaC) using Terraform.\n\u2502  \n\u251c\u2500\u2500 \ud83d\udc0d  Python+Scripting       \u2192 Python automation, scripting, and DevOps tools.\n\u2502  \n\u251c\u2500\u2500 \ud83d\udc27  Linux+Scripting        \u2192 Linux commands, Bash scripting, and automation.\n\u2502  \n\u251c\u2500\u2500 \ud83d\udc33  Docker                 \u2192 Application Containerization\n\u2502\n\u251c\u2500\u2500 \ud83d\udcca  Monitoring &amp; Logging   \u2192 Logging, Prometheus, Grafana, and observability tools.\n\u2502  \n\u2514\u2500\u2500 \ud83d\udd00  Git                    \u2192 Version control, branching strategies, and workflows.\n</code></pre>"},{"location":"%F0%9F%9A%80%20Ram-Portfolio/","title":"\ud83d\ude80 Ram Portfolio","text":""},{"location":"%F0%9F%9A%80%20Ram-Portfolio/#ram-portfolio","title":"\ud83d\ude80 Ram Portfolio","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/","title":"Index","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/#k8s-index","title":"K8s Index","text":"<p>Use the links \ud83d\udc47 to navigate through topics if needed.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/#core-concepts","title":"\ud83d\udcd8 Core Concepts","text":"<ul> <li>1.1 Kubernetes Architecture</li> <li>1.2 Kubernetes Components</li> <li>1.3 Kubernetes Services</li> <li>1.4 Kubernetes Namespaces</li> <li>1.5 Imperative and Declarative Approaches</li> <li>1.6 Practice Resources</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.1%20k8s-architecture/","title":"1.1 k8s architecture","text":"Credits <p>This documentation is based on the Certified Kubernetes Administrator (CKA) with Practice Tests Udemy course by Mumshad Mannambeth, with supporting labs from KodeKloud.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.1%20k8s-architecture/#official-kubernetes-documentation","title":"Official Kubernetes documentation","text":"<p>Note</p> <p>The <code>crictl</code> is from the Kubernetes community and works across all CRI compatible runtimes and are used mainly for debugging purposes.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.1%20k8s-architecture/#available-cris-containerd-rkt","title":"Available CRI's - <code>ContainerD</code>, <code>\ud83d\ude80rkt</code>","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.1%20k8s-architecture/#watch-the-video","title":"Watch the Video","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.2%20k8s-components/","title":"1.2 k8s components","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.2%20k8s-components/#kubernetes-components","title":"Kubernetes Components","text":"1. ETCD (Click to Expand) 2.Kube-Api Server  (Click to Expand) 3.Kube Controller Manager  (Click to Expand) 4.kube-scheduler (Click to Expand) 5.kubelet (Click to Expand) 6.kube-proxy (Click to Expand) 7.Pods (Click to Expand) 8. ReplicaSets (Click to Expand) 9. Deployment (Click to Expand)"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.2%20k8s-components/#etcd","title":"ETCD","text":"<ul> <li> <p>The etcd key value data store stores information regarding the cluster such as the nodes, pods, convicts, secrets, accounts, roles,role bindings, and others. Every information you see when you run the kube control get command is from the etcd server.</p> </li> <li> <p>Every change you make to your cluster such as adding additional nodes, deploying pods or replica sets are updated in the etcd server. Only once it is updated in the etcd server is the change considered to be complete. </p> </li> <li> <p>ETCD V3 Commands </p> </li> <li> <p>If you set up your cluster using kubeadm, then kubeadm deploys the etcd server for you as a pod in the kube system namespace. </p> </li> <li> <p>In a high availability(HA) environment, you will have multiple master nodes in your cluster. Then you will have multiple etcd instances spread across the master nodes. In that case, make sure that the etcd instances know about each other by setting the right parameter in the etcd service configuration.</p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.2%20k8s-components/#kube-api-server","title":"Kube-Api Server","text":"<ul> <li> <p>Let's look at an example of creating a pod. When you do that, as before,the request is authenticated first and then validated. In this case, the API server creates a pod object without assigning it to a node.Updates the information in the etcd server,updates the user that the pod has been created.</p> </li> <li> <p>The scheduler continuously monitors the API server and realizes that there is a new pod with no node assigned.The scheduler identifies the right worker node to place the new pod on. The API server then updates the informationin the etcd cluster.The API server then passes that information to the kubelet in the appropriate worker node.The kubelet then creates the podon the node and instructs the container runtime engineto deploy the application image.Once done, the kubelet updates the statusback to the API serverand the API server then updates the databack in the etcd cluster. A similar pattern is followed every time a change is requested. The kube-apiserver is at the center of all the different tasks that needs to be performed to make a change in the cluster.</p> </li> <li> <p>To summarize, the kube-apiserver is responsible for authenticating and validating requests, retrieving and updating data in the etcd data store. In fact, kube-apiserver is the only component that interacts directly with the etcd data store. The other components, such as the scheduler, kube-controller-manager and kubelet uses the API server to perform updates in the cluster in their respective areas.</p> </li> </ul> <p></p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.2%20k8s-components/#kube-controller-manager","title":"Kube Controller Manager","text":"<ul> <li> <p>A controller is a process that continuously monitors the state of various components within the system and works towards bringing the whole system to the desired functioning state.</p> </li> <li> <p>For example, the node controller is responsible for monitoring the status of the nodes and taking necessary actions to keep the applications running. It does that through the Kube API server. The node controller tests the status of the nodes every five seconds. That way the node controller can monitor the health of the nodes. If it stops receiving heartbeat from a node the node is marked as unreachable but it waits for 40 seconds before marking it unreachable. After a node is marked unreachable it gives it 5 minutes to come back up. If it doesn't, it removes the PODs assigned to that node and provisions them on the healthy ones. </p> </li> <li> <p>if the PODs are part of a replica set. The next controller is the replication controller. It is responsible for monitoring the status of replica sets and ensuring that the desired number of PODs are available at all times within the set. If a POD dies, it creates another one. Now, those were just two examples of controllers. There are many more such controllers available within Kubernetes. </p> </li> <li> <p>Now, how do you see these controllers and where are they located in your cluster? They're all packaged into a single process known as the Kubernetes Controller Manager. When you install the Kubernetes controller manager the different controllers get installed as well.</p> </li> </ul> <p></p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.2%20k8s-components/#kube-scheduler","title":"kube-scheduler","text":"<ul> <li> <p>The scheduler looks at each pod and tries to find the best node for it.For example, let's take one of these pods, the big blue one.It has a set of CPU and memory requirements.The scheduler goes through two phasesto identify the best node for the pod.In the first phase, the scheduler tries to filter outthe nodes that do not fit the profile for this pod.For example, the nodes that do not have sufficient CPU and memory resources requested by the pod.So the first two small nodes are filtered out.So we are now left with the two nodeson which the pod can be placed.Now how does the scheduler pick one from the two?The scheduler ranks the nodesto identify the best fit for the pod.It uses a priority function to assign a scoreto the nodes on a scale of zero to 10.For example, the scheduler calculatesthe amount of resources that would be freeon the nodes after placing the pod on them.In this case, the one on the rightwould have six CPUs free if the pod was placed on it,which is four more than the other one.So it gets a better rank, and so it wins. </p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.2%20k8s-components/#note-remember-the-scheduler-is-only-responsiblefor-deciding-which-pod-goes-on-which-nodeit-doesnt-actually-place-the-pod-on-the-nodesthats-the-job-of-the-kubelet","title":"Note: Remember, the scheduler is only responsiblefor deciding which pod goes on which node.It doesn't actually place the pod on the nodes.That's the job of the kubelet.","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.2%20k8s-components/#kubelet","title":"kubelet","text":"<ul> <li> <p>The kubelet in the Kubernetes worker node registers the node with a Kubernetes cluster. When it receives instructions to load container or a pod on the node,it requests the container runtime engine,which may be Docker, to pull the required image and run an instance.The kubelet then continues to monitor the state of the pod and containers in it and reports to the kube API serveron a timely basis.</p> </li> <li> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.2%20k8s-components/#note-so-how-do-you-install-the-kubelet-if-you-use-the-kubeadm-tool-to-deploy-your-clusterit-does-not-automatically-deploy-the-kubelet-now-thats-the-difference-from-other-componentsyou-must-always-manually-install-the-kubelet-on-your-worker-nodes","title":"Note: So how do you install the kubelet? If you use the kubeadm tool to deploy your cluster,it does not automatically deploy the kubelet. Now that's the difference from other components.You must always manually install the kubelet on your worker nodes.","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.2%20k8s-components/#kube-proxy-networking-and-communication","title":"kube-proxy (networking and Communication)","text":"<ul> <li> <p>Kube-proxy is a process that runs on each node in the Kubernetes cluster. Its job is to look for new services, and every time a new service is created, it creates the appropriate rules on each node to forward traffic to those services to the backend pods. One way it does this is using iptables rules. In this case, it creates an iptables rule on each node in the cluster to forward traffic heading to the IP of the service, which is 10.96.0.12, to the IP of the actual pod, which is 10.32.0.15. So that's how kube-proxy configures a service. </p> </li> <li> <p>The kubeadm tool deploys kube-proxy as pods on each node. In fact, it is deployed as a DaemonSet, so a single pod is always deployed on each node in the cluster. </p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.2%20k8s-components/#pods","title":"Pods","text":"<ul> <li> <p>A pod is a single instance of an application. A pod is the smallest object that you can create in Kubernetes. Here we see the simplest of simplest cases where you have a single-node Kubernetes cluster with a single instance of your application running in a single Docker container encapsulated in a pod.</p> </li> <li> <p>What if the number of users accessing your application increase and you need to scale your application? We create a new pod altogether with a new instance of the same application. As you can see, we now have two instances of our web application running on two separate pods on the same Kubernetes system or node.</p> </li> </ul> <p></p> <ul> <li> <p>What if the user base further increases and your current node has no sufficient capacity? Well, then you can always deploy additional pods on a new node in the cluster.</p> </li> <li> <p>You will have a new node added to the cluster to expand the cluster's physical capacity. Pods usually have a one-to-one relationship with containers running your application. To scale up, you create new pods, and to scale down, you delete existing pods. You do not add additional containers to an existing pod to scale your application.</p> </li> </ul> <p></p> <ul> <li>So in the current state, we haven't made the web server accessible to external users. You can, however, access it internally from the node. Once we learn about networking and services, we will get to know how to make this service accessible to end users.</li> </ul> Pod Configuration in YAML (Click to Expand) <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    app: myapp            # Label 1\n    type: backend-process # Label 2\nspec:\n  containers:\n    - name: myapp-container\n      image: &lt;Image&gt;\n      resources:\n        limits:\n          memory: \"128Mi\"\n          cpu: \"500m\"\n      ports:\n        - containerPort: 8080\n</code></pre> <p> </p> <ul> <li>Containers is a list or an array. The reason this property is a list is because the pods can have multiple containers within them</li> </ul> Commands to Create Pod and describe pod (Click to Expand) pod-definition.yaml<pre><code>kubectl create -f pod-definition.yaml\n</code></pre> To Get Pods<pre><code>kubectl get pods\n</code></pre> To Describe Pods<pre><code>kubectl describe pod myapp-pod\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.2%20k8s-components/#replicasets","title":"ReplicaSets","text":"<ul> <li> <p>To prevent users from losing access to our application, we would like to have more than one instance or pod running at the same time. That way, if one fails we still have our application running on the other one. The Replication Controller helps us run multiple instances of a single pod in the Kubernetes cluster.</p> </li> <li> <p>Even if you have a single pod, the Replication Controller can help by automatically bringing up a new pod when the existing one fails. Thus, the Replication Controller ensures that the specified number of pods are running at all times even if it's just one or 100. Another reason we need Replication Controller is to create multiple pods to share the load across them. </p> </li> <li> <p>If the demand further increases and if we were to run out of resources on the first node we could deploy additional parts across the other nodes in the cluster. As you can see, the Replication Controller spans across multiple nodes in the cluster. It helps us balance the load across multiple pods on different nodes as well as scale our application when the demand increases.</p> </li> </ul> ReplicaSet Configuration in YAML (Click to Expand) <pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: myreplicaset\n  labels:\n    app: myapp\n    key: value\nspec:\n  replicas: &lt;Replicas&gt;\n  selector:\n    matchLabels:\n      key: value\n  template:\n    metadata:\n      labels:\n        key: value\n    spec:\n      containers:\n        - name: myapp\n          image: &lt;Image&gt;\n</code></pre> <ul> <li> <p>Replica Set can also manage pods that were not created as part of the Replica Set creation. Say for example, there were pods created before the creation of the Replica Set that match labels specified in the selector, the Replica Set will also take those pods into consideration when creating the replicas.</p> </li> <li> <p>The role of the Replica Set is to monitor the pods and if any of them were to fail, deploy new ones. The Replica Set is in fact a process that monitors the pods. Now, how does the Replica Set know what pods to monitor? There could be hundreds of other pods in the cluster running different applications. This is where labeling our pods during creation comes in handy. We could now provide these labels as a filter for Replica Set. Under the selector section, we use the match labels filter and provide the same label that we used while creating the pods.This way, the Replica Set knows which pods to monitor. The same concept of labels and selectors is used in many other places throughout Kubernetes.</p> </li> </ul> ReplicaSet Commands replicaset-definition.yaml<pre><code>    kubectl create -f replicaset-definition.yaml\n</code></pre> To Get replicaset<pre><code>    kubectl get replicaset\n</code></pre> To Describe Pods<pre><code>    kubectl describe pod myapp-pod\n</code></pre> To Replace ReplicaSet Definition<pre><code>    kubectl replace -f replicaset-definition.yml\n</code></pre> To Scale ReplicaSet using file<pre><code>    kubectl scale --replicas=6 -f replicaset-definition.yml\n</code></pre> To Scale ReplicaSet using name<pre><code>    kubectl scale --replicas=6 replicaset myapp-replicaset\n</code></pre> Delete ReplicaSet (also deletes all underlying pods)<pre><code>    kubectl delete replicaset replicaset-name\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.2%20k8s-components/#deployment","title":"Deployment","text":"Deployment Configuration in YAML (Click to Expand) <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n        - name: myapp\n          image: &lt;Image&gt;\n          resources:\n            limits:\n              memory: \"128Mi\"\n              cpu: \"500m\"\n          ports:\n            - containerPort: &lt;Port&gt;\n</code></pre> Deployment Commands Deployment-definition.yaml<pre><code>    kubectl create -f Deployment-definition.yaml\n</code></pre> To see all the created objects at once<pre><code>    kubectl get all\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.3%20K8s-services/","title":"1.3 K8s services","text":"<p>Kubernetes Services facilitate communication both within the application and with external users. They connect different groups of Pods\u2014such as frontend, backend, and those interacting with external data sources\u2014allowing them to work together seamlessly. Services ensure the frontend is accessible to users, enable backend-frontend interaction, and support connections to external systems. This allows for loose coupling between microservices, making the application more modular and scalable.</p> <p></p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.3%20K8s-services/#kubernetes-offers-three-main-types-of-services-for-exposing-applications","title":"Kubernetes offers three main types of Services for exposing applications","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.3%20K8s-services/#node-port-service","title":"Node Port Service","text":"<p>Exposes a Pod on a specific port of the node, making it accessible externally.   The Kubernetes Service is an object, just like Pods, ReplicaSets, or Deployments. One of its use cases is to listen to a port on the node and forward requests on that port to a port on the Pod running the web application.   This type of Service is known as a NodePort Service because it listens on a port on the node and forwards requests to the Pods.</p> <p> </p> Node Port Configuration (Click to Expand) <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\nspec:\n  selector:\n    app: myapp\n  ports:\n  - port: &lt;Port&gt;\n    targetPort: &lt;Target Port&gt;\n</code></pre> <ul> <li>If the Pods are distributed across multiple nodes  </li> </ul> <p>To summarize, in any case, whether it be a single Pod on a single node, multiple Pods on a single node, or multiple Pods on multiple nodes, the service is created exactly the same without you having to do any additional steps during the service creation. When Pods are removed or added, the service is automatically updated,</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.3%20K8s-services/#cluster-ip-service","title":"Cluster IP Service","text":"<p>Creates a virtual IP within the cluster, allowing internal communication between services like frontend and backend.  </p> <ul> <li> <p>Pods in Kubernetes are assigned IP addresses, but these are not static\u2014pods can be recreated at any time, making direct IP-based communication unreliable. For instance, if a frontend pod needs to talk to the backend, how does it know which backend pod to connect to?</p> </li> <li> <p>This is where a Kubernetes Service helps. It groups similar pods (like backend pods) under a single stable IP and DNS name, enabling reliable internal communication. The service automatically load balances requests across the pods in the group.</p> </li> <li> <p>Similarly, you can create a service for Redis so backend pods can communicate with it reliably. This setup supports scalable microservices, where each layer can grow or change independently without breaking communication.Such a service is called a ClusterIP service, and it's the standard way for pods to talk to each other inside the cluster.</p> </li> </ul> ClusterIP Service Configuration (Click to Expand) <pre><code># service-definition.yml\napiVersion: v1\nkind: Service\nmetadata:\n  name: back-end\nspec:\n  type: ClusterIP\n  ports:\n    - targetPort: 80\n      port: 80\n  selector:\n    app: myapp\n    type: back-end\n</code></pre> <ul> <li> <p>The targetPort refers to the port on which the backend pod is running (in this case, 80), while the port is the one exposed by the service itself\u2014also set to 80 here. The selector is used to connect the service to the appropriate set of pods.</p> </li> <li> <p>In fact, cluster IP is the default type so even if you didn't specify it it will automatically assume the type to be cluster IP.</p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.3%20K8s-services/#loadbalancer-service","title":"LoadBalancer Service","text":"Load Balancer Servive Configuration (Click to Expand) <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\nspec:\n  type: LoadBalancer\n  selector:\n    app: myapp\n  ports:\n    - port: 80\n      targetPort: 80\n</code></pre> <ul> <li> <p>To make your application accessible to users, they need a single, consistent URL\u2014like votingapp.com or resultapp.com\u2014instead of dealing with node IPs and ports.</p> </li> <li> <p>If you're using a supported cloud platform such as Google Cloud, AWS, or Azure, you can take advantage of their built-in load balancer. To do this, simply set the service type of your frontend services to LoadBalancer instead of NodePort.</p> </li> <li> <p>Keep in mind, this approach only works on platforms that support this feature\u2014GCP, AWS, and Azure are all supported.</p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.3%20K8s-services/#kubernetes-service-types-comparison","title":"\ud83d\udd01 Kubernetes Service Types: Comparison","text":"Service Type Description Access Scope Use Case ClusterIP Default service type. Exposes the service on an internal IP within the cluster. Internal only Internal communication between pods/services. NodePort Exposes the service on a static port on each node\u2019s IP. Internal + External access via <code>&lt;NodeIP&gt;:&lt;NodePort&gt;</code> Basic external access (e.g., dev/test environments). LoadBalancer Provisions an external load balancer and exposes the service to the internet. External (cloud platforms only) Production-level public access. <p>\ud83e\udde0 When to Use What?</p> <ul> <li> <p>ClusterIP: Use when services only need to communicate within the cluster (e.g., frontend talks to backend, backend to database).</p> </li> <li> <p>NodePort: Use when you need basic external access to a service (for testing or non-production environments). Requires using <code>&lt;NodeIP&gt;:&lt;NodePort&gt;</code>.</p> </li> <li> <p>LoadBalancer: Use in cloud environments (AWS, GCP, Azure) when you want a public URL/IP for external access. It automatically handles provisioning of a load balancer.</p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.4%20K8s-NameSpaces/","title":"1.4 K8s NameSpaces","text":"<p>Kubernetes creates three default namespaces at cluster setup:</p> <ul> <li> <p>default: For general user workloads.</p> </li> <li> <p>kube-system: For internal Kubernetes components (like networking, DNS).</p> </li> <li> <p>kube-public: For resources accessible to all users.</p> </li> <li> <p>While small or learning environments can work within the default namespace, larger or production setups benefit from custom namespaces (e.g., dev, prod) to isolate resources, apply access policies, and manage resource quotas. This helps prevent accidental changes and ensures better organization and control.</p> </li> <li> <p>In Kubernetes, resources within the same namespace can communicate using just their names (e.g., a web pod can reach a DB service by using dbservice). To access services across namespaces, use the full DNS format: servicename.namespace.svc.cluster.local (e.g., dbservice.dev.svc.cluster.local). Kubernetes automatically creates these DNS entries, where cluster.local is the default cluster domain and svc indicates it\u2019s a service.</p> </li> </ul> <p> </p> NameSpace Commands (Click to Expand) Get Pods in a namespace<pre><code>    kubectl get pods --namespace=kube-system\n\n    (OR)\n\n    kubectl get pods --all-namespaces  #getting pods in all namespaces\n</code></pre> Create pods in another namespace<pre><code>    kubectl create -f pod-definition.yml --namespace=dev\n</code></pre> Set Another Namespace As Default  (Click to Expand) <ul> <li>But what if we want to switch to the <code>dev</code> namespace permanently, so that we don't have to specify the <code>--namespace</code> option anymore?</li> </ul> Set Default Namespace for kubectl<pre><code>kubectl config set-context $(kubectl config current-context) --namespace=dev\n</code></pre> ResourceQuota Configuration (Click to Expand) <ul> <li>To limit resources in a namespace, create a resource quota.</li> </ul> <pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: compute-quota\n  namespace: dev\nspec:\n  hard:\n    pods: \"10\"\n    requests.cpu: \"4\"\n    requests.memory: 5Gi\n    limits.cpu: \"10\"\n    limits.memory: 10Gi\n</code></pre> <p></p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.4%20K8s-NameSpaces/#pod-definition-with-namespace","title":"Pod Definition with Namespace","text":"Pod Configuration (Click to Expand) <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: myapp-pod\nnamespace: dev\nlabels:\n    app: myapp\n    type: front-end\nspec:\ncontainers:\n    - name: nginx-container\n    image: nginx\n</code></pre> Create Namespace<pre><code>    kubectl create namespace dev (OR)\n    kubectl create -f namespace-dev.yml\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.4%20K8s-NameSpaces/#namespace-definition","title":"Namespace Definition","text":"Namespace Creation Definition (Click to Expand) <pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\nname: dev\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/","title":"1.5 imperative and declarative approaches","text":"<ul> <li>Note : A more effective approach is to first modify the local copy of the object\u2019s configuration file by updating the image name as needed, and then use the kubectl replace command to apply the changes and update the object.</li> </ul> <ul> <li> <p>The declarative approach involves using the same object configuration files we've been working with. However, instead of using the create or replace commands, we use kubectl apply to manage the objects.</p> </li> <li> <p>The kubectl apply command is smart enough to create an object if it doesn\u2019t already exist. When working with multiple configuration files \u2014 which is common \u2014 you can specify a directory path rather than a single file, allowing all the objects in that directory to be created at once.</p> </li> <li> <p>To make changes, simply update the relevant configuration file and run kubectl apply again. If the object already exists, apply will detect that and only apply the necessary updates.</p> </li> <li> <p>This approach avoids errors about objects already existing or updates being invalid \u2014 kubectl apply automatically figures out the correct way to update the object based on the changes you've made.</p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#certification-tips-imperative-commands-with-kubectl","title":"Certification Tips \u2013 Imperative Commands with Kubectl","text":"<p>While you will mostly use the declarative approach with definition files, imperative commands are useful for quickly completing one-time tasks or generating YAML templates. This can save significant time during certification exams.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#key-options","title":"\ud83d\udd27 Key Options","text":"<ul> <li> <p><code>--dry-run=client</code>   Prevents the resource from being created. Useful for testing commands without making changes.</p> </li> <li> <p><code>-o yaml</code>   Outputs the object definition in YAML format.</p> </li> </ul> <p>\ud83d\udca1 Tip: Use both options together to generate definition files you can edit and apply later.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#pod","title":"\ud83d\udc33 POD","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#create-an-nginx-pod","title":"Create an NGINX Pod","text":"<pre><code>kubectl run nginx --image=nginx\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#generate-pod-yaml-manifest-dry-run","title":"Generate POD YAML Manifest (dry-run)","text":"<pre><code>kubectl run nginx --image=nginx --dry-run=client -o yaml\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#deployment","title":"\ud83d\ude80 Deployment","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#create-a-deployment","title":"Create a Deployment","text":"<pre><code>kubectl create deployment --image=nginx nginx\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#generate-deployment-yaml-dry-run","title":"Generate Deployment YAML (dry-run)","text":"<pre><code>kubectl create deployment --image=nginx nginx --dry-run=client -o yaml\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#create-deployment-with-4-replicas","title":"Create Deployment with 4 Replicas","text":"<pre><code>kubectl create deployment nginx --image=nginx --replicas=4\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#scale-a-deployment","title":"Scale a Deployment","text":"<pre><code>kubectl scale deployment nginx --replicas=4\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#generate-and-save-deployment-yaml-to-file","title":"Generate and Save Deployment YAML to File","text":"<pre><code>kubectl create deployment nginx --image=nginx --dry-run=client -o yaml &gt; nginx-deployment.yaml\n</code></pre> <p>Then, update the YAML file to add replicas or modify other fields before applying.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#service","title":"\ud83c\udf10 Service","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#create-clusterip-service-for-pod-redis-on-port-6379","title":"Create ClusterIP Service for Pod <code>redis</code> on Port 6379","text":"<pre><code>kubectl expose pod redis --port=6379 --name redis-service --dry-run=client -o yaml\n</code></pre> <p>\u2705 Automatically uses the pod's labels as selectors.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#alternative-create-clusterip-service-manual-selectors-required","title":"Alternative: Create ClusterIP Service (Manual Selectors Required)","text":"<pre><code>kubectl create service clusterip redis --tcp=6379:6379 --dry-run=client -o yaml\n</code></pre> <p>\u26a0\ufe0f Does not use pod labels. Assumes <code>app=redis</code> as selector.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#create-nodeport-service-for-pod-nginx-exposing-port-80-on-nodeport-30080","title":"Create NodePort Service for Pod <code>nginx</code> Exposing Port 80 on NodePort 30080","text":"<pre><code>kubectl expose pod nginx --type=NodePort --port=80 --name=nginx-service --dry-run=client -o yaml\n</code></pre> <p>\u2705 Uses pod's labels as selectors \u26a0\ufe0f You cannot specify the nodePort in this command \u2014 must edit YAML manually</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#alternative-specify-nodeport-manual-selectors-required","title":"Alternative: Specify NodePort (Manual Selectors Required)","text":"<pre><code>kubectl create service nodeport nginx --tcp=80:80 --node-port=30080 --dry-run=client -o yaml\n</code></pre> <p>\u26a0\ufe0f Does not use pod's labels as selectors</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#recommendation","title":"\u2705 Recommendation","text":"<p>Use <code>kubectl expose</code> to generate the YAML and manually add the <code>nodePort</code> before applying it.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.5%20imperative%20and%20declarative%20approaches/#references","title":"\ud83d\udcda References","text":"<ul> <li>kubectl Command Reference </li> <li>kubectl Conventions</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.6%20practice-resources/","title":"1.6 practice resources","text":"CKA Exam Domains &amp; Weightage (Click to Expand) <p>1. Cluster Architecture, Installation &amp; Configuration (25%) <pre><code>- Manage role based access control (RBAC)\n- Prepare underlying infrastructure for installing a Kubernetes cluster\n- Create and manage Kubernetes clusters using kubeadm\n- Manage the lifecycle of Kubernetes clusters\n- Implement and configure a highly-available control plane\n- Use Helm and Kustomize to install cluster components\n- Understand extension interfaces (CNI, CSI, CRI, etc.)\n- Understand CRDs, install and configure operators\n</code></pre></p> <p>2. Workloads &amp; Scheduling (15%) <pre><code>- Understand application deployments and how to perform rolling update and rollbacks\n- Use ConfigMaps and Secrets to configure applications\n- Configure workload autoscaling\n- Understand the primitives used to create robust, self-healing, application deployments\n- Configure Pod admission and scheduling (limits, node affinity, etc.)\n</code></pre></p> <p>3. Services &amp; Networking (20%) <pre><code>- Understand connectivity between Pods\n- Define and enforce Network Policies\n- Use ClusterIP, NodePort, LoadBalancer service types and endpoints\n- Use the Gateway API to manage Ingress traffic\n- Know how to use Ingress controllers and Ingress resources\n- Understand and use CoreDNS\n</code></pre></p> <p>4. Storage (10%) <pre><code>- Implement storage classes and dynamic volume provisioning\n- Configure volume types, access modes and reclaim policies\n- Manage persistent volumes and persistent volume claims\n</code></pre></p> <p>5. Troubleshooting (30%) <pre><code>- Troubleshoot clusters and nodes\n- Troubleshoot cluster components\n- Monitor cluster and application resource usage\n- Manage and evaluate container output streams\n- Troubleshoot services and networking\n</code></pre></p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.6%20practice-resources/#cka-exam-dumps","title":"CKA Exam Dumps","text":"CKA Exam Dumps \u2013 itexams.com <p>     Browse sample questions and practice tests for the Certified Kubernetes Administrator (CKA) exam.     Includes realistic exam-like scenarios.   </p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.6%20practice-resources/#kodekloud","title":"KodeKloud","text":"<ul> <li>Free practice labs</li> <li>Solution Videos</li> <li>Community Support</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.6%20practice-resources/#killercodacom","title":"killercoda.com","text":"<ul> <li>Interactive K8s environment</li> <li>Real-time feedback</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.6%20practice-resources/#play-with-k8scom","title":"play-with-k8s.com","text":"<ul> <li>4-hour free clusters</li> <li>Multi-node setup</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/1.Core-Concepts/1.7%20practice-links/","title":"1.7 practice links","text":"<p>Credits: The following practice tests are from KodeKloud Labs and are part of the Kubernetes Udemy course by Mumshad Mannambeth.</p> <ul> <li>Practice Test - Pods </li> <li>Practice Test - ReplicaSets </li> <li>Practice Test - Deployments </li> <li>Practice Test - Services </li> <li>Practice Test - Namespaces </li> <li>Practice Test - Imperative Commands </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.01%20Manual-Scheduling/","title":"2.01 Manual Scheduling","text":"Credits <p>This documentation is based on the Certified Kubernetes Administrator (CKA) with Practice Tests Udemy course by Mumshad Mannambeth, with supporting labs from KodeKloud.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.01%20Manual-Scheduling/#working-of-scheduler-in-kubernetes","title":"Working of Scheduler in Kubernetes","text":"<ul> <li>Each pod has a <code>nodeName</code> field, which is empty by default.  </li> <li>You usually don\u2019t set this field in the manifest\u2014Kubernetes sets it automatically.  </li> <li>The scheduler looks for pods without a <code>nodeName</code>.  </li> <li>It runs its algorithm to find a suitable node.  </li> <li>Once identified, it schedules the pod by setting <code>nodeName</code> through a binding object.  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.01%20Manual-Scheduling/#scheduling-without-a-scheduler","title":"Scheduling Without a Scheduler","text":"<p>If there is no scheduler, pods will remain in the Pending state. You can still assign them manually in two ways:</p> Case How it Works Notes During Pod Creation Set the <code>nodeName</code> field in the pod spec before creating the pod. Kubernetes then assigns the pod to that node. \u2022 Only possible at creation time.\u2022 Simple and direct method. After Pod Creation Create a Binding object and send a POST request to the Pods Binding API, specifying the target node in JSON format. \u2022 <code>nodeName</code> cannot be modified after creation.\u2022 Mimics the scheduler\u2019s binding process.\u2022 Requires YAML \u2192 JSON conversion."},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.01%20Manual-Scheduling/#troubleshooting-pods-in-pending-state","title":"Troubleshooting Pods in Pending State","text":"<p>If a pod is stuck in the Pending state, use the following checklist:</p> Area What to Check Command(s) Pod Events and Description Review events for scheduling errors or resource issues (CPU, memory, storage). <code>kubectl describe pod &lt;pod-name&gt;</code> Node Status Ensure nodes are Ready and have enough free CPU, memory, and disk space. <code>kubectl get nodes</code><code>kubectl describe node &lt;node-name&gt;</code> Scheduler Availability Verify kube-scheduler is running. If it\u2019s down, pods will remain Pending. (Check scheduler pod logs in managed clusters) Resource Requests and Limits Confirm pod <code>resources.requests</code> don\u2019t exceed node capacity. Compare with available resources. (Check pod spec and node resources with <code>kubectl describe</code>) Taints and Tolerations Check if nodes have taints; pods need matching tolerations. <code>kubectl describe node &lt;node-name&gt; \\| grep Taints</code> Node Selectors and Affinity Validate scheduling rules like <code>nodeSelector</code>, <code>nodeAffinity</code>, or <code>podAffinity</code>/<code>podAntiAffinity</code>. (Check pod spec YAML) Persistent Volumes and Claims Ensure PVCs are bound and a matching PV exists. <code>kubectl get pvc</code>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.01%20Manual-Scheduling/#quick-reference","title":"\u2705 Quick Reference","text":"<ol> <li>Check Pod Events \u2192 <code>kubectl describe pod</code>.  </li> <li>Check Nodes \u2192 <code>kubectl get nodes</code> \u2192 <code>kubectl describe node</code>.  </li> <li>Confirm Scheduler is running.  </li> <li>Validate Resource Requests/Limits.  </li> <li>Inspect Taints/Tolerations.  </li> <li>Review Node Selectors / Affinity rules.  </li> <li>Verify PVCs and PVs.  </li> </ol>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.02%20Labels-and-Selectors/","title":"2.02 Labels and Selectors","text":"<ul> <li>For example, here's a manifest for a Pod that has two labels environment: production and app: nginx:</li> </ul> Pod Labels Configuration in YAML (Click to Expand) <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: label-demo\n  labels:\n    environment: production  # Label 1\n    app: nginx               # Label 2\nspec:\n  containers:\n    - name: nginx\n      image: nginx:1.14.2\n      ports:\n        - containerPort: 80\n</code></pre> <p>Select Pods using a Label Selector<pre><code>kubectl get pods --selector app=nginx (or)\nkubectl get pods -l env=prod,bu=finance,tier=frontend #if Pods have multiple labels\n\n\ud83d\udd0e Explanation:\n-l (or --selector) lets you filter by labels.\nComma-separated labels mean AND condition \u2192 Pod must match all of them.\n</code></pre> </p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.02%20Labels-and-Selectors/#annotation","title":"Annotation","text":"<ul> <li> <p>Labels and selectors are primarily used to group and identify Kubernetes objects, whereas annotations serve to store additional information for reference.</p> </li> <li> <p>For instance, annotations can capture details such as tool name, version, build information, and other metadata.</p> </li> </ul> Pod with Annotation in YAML (Click to Expand) <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: annotations-demo\n  annotations:\n    imageregistry: \"https://hub.docker.com/\"  # Annotation\nspec:\n  containers:\n    - name: nginx\n      image: nginx:1.14.2\n      ports:\n        - containerPort: 80\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.03%20Taints-and-Tolerations/","title":"2.03 Taints and Tolerations","text":"<p>Taint (on Node): says \u201cdon\u2019t accept certain Pods unless they have permission.\u201d Toleration (on Pod): is that permission which allows the Pod to run on a tainted Node.  </p> <p>Key Point</p> <ul> <li>Taints keep Pods away from Nodes.  </li> <li>Tolerations let Pods through, but don\u2019t force them onto that Node.  </li> <li>To force Pods onto specific Nodes, use Node Affinity.  </li> <li>Remember: Taints are set on Nodes and Tolerations are set on Pods.  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.03%20Taints-and-Tolerations/#taint-effects","title":"Taint Effects","text":"<p>Taints can have 3 different effects:</p> <ul> <li>NoSchedule \u2192 Pod without toleration will not be scheduled on the node.  </li> <li>PreferNoSchedule \u2192 Kubernetes tries not to schedule Pods without toleration, but may still do so if needed.  </li> <li>NoExecute \u2192 Pod without toleration will be evicted if it\u2019s already running, and new Pods without toleration won\u2019t be scheduled.  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.03%20Taints-and-Tolerations/#example","title":"Example","text":"<p>We now have 3 nodes, each with a different taint effect:</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.03%20Taints-and-Tolerations/#nodes-their-taints","title":"Nodes &amp; Their Taints","text":"<ul> <li>Node 1 \u2013 NoSchedule \ud83d\udc49 Pod without toleration \u274c won\u2019t be scheduled.  </li> <li>Node 2 \u2013 PreferNoSchedule \ud83d\udc49 Pod \u26a0\ufe0f might still be scheduled if no better option.  </li> <li>Node 3 \u2013 NoExecute \ud83d\udc49 Pod \u26d4 is evicted if already running, and new ones are blocked.  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.03%20Taints-and-Tolerations/#pods-in-this-scenario","title":"Pods in This Scenario","text":"<ul> <li>Pod 1 \u2192 no toleration  </li> <li>Pod 2 \u2192 no toleration  </li> <li>Pod 3 \u2192 tolerates Node 2\u2019s taint  </li> <li>Pod 4 \u2192 tolerates Node 1\u2019s taint  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.03%20Taints-and-Tolerations/#taint-syntax","title":"Taint Syntax","text":"Add a Taint to a Node<pre><code>kubectl taint nodes &lt;node-name&gt; &lt;key&gt;=&lt;value&gt;:&lt;effect&gt;\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.03%20Taints-and-Tolerations/#taint-example","title":"Taint Example","text":"Add a Taint to Node1<pre><code>kubectl taint nodes node1 app=blue:NoSchedule\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.03%20Taints-and-Tolerations/#tolerations-example","title":"Tolerations example","text":"Tolerations for the pod<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\nspec:\n  containers:\n    - name: nginx-container\n      image: nginx\n  tolerations:\n    - key: \"app\"\n      operator: \"Equal\"\n      value: \"blue\"\n      effect: \"NoSchedule\"\n</code></pre> <p>Note</p> <p>Remember, all of these values inside tolerations need to be encoded in double quotes.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.03%20Taints-and-Tolerations/#master-node-taints","title":"Master Node Taints","text":"<ul> <li> <p>Master nodes can technically run Pods like worker nodes, but by default the scheduler avoids them. This is because a taint is automatically applied to master nodes when the cluster is first set up.  </p> </li> <li> <p>You can view or modify this taint if needed, but best practice is not to run application workloads on master nodes.  </p> </li> </ul> Check Taints on Master Node<pre><code>kubectl describe node &lt;master-node-name&gt; | grep Taint\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.03%20Taints-and-Tolerations/#remove-a-taint-from-a-node","title":"Remove a Taint from a Node","text":"<ul> <li> <p>To remove a taint from a node in Kubernetes, you append a <code>-</code> at the end of the taint specification.  </p> </li> <li> <p>For example, to remove the NoSchedule taint from the <code>controlplane</code> node, run:  </p> </li> </ul> Remove NoSchedule Taint from controlplane<pre><code>kubectl taint nodes controlplane node-role.kubernetes.io/control-plane:NoSchedule-\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.04%20Node-Selectors/","title":"2.04 Node Selectors","text":"<ul> <li>Cluster has 3 nodes: 2 small (limited resources) and 1 large (higher capacity).  </li> <li>Heavy data-processing jobs should run on the large node.  </li> <li>By default, Kubernetes can schedule pods on any node.  </li> <li>This may place heavy pods on small nodes, which is not desired.  </li> <li>To avoid this, restrict pods to specific nodes using node selectors (simplest method).  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.04%20Node-Selectors/#nodeselector-example","title":"NodeSelector Example","text":"<p>Important</p> <ul> <li>Nodes are labeled with key-value pairs (e.g., <code>size=large</code>).  </li> <li>The scheduler uses these labels to decide where to place pods.  </li> <li>Nodes must be labeled before using them in a <code>nodeSelector</code>.  </li> </ul> Node Labeling Command<pre><code>kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;\n# Example: kubectl label nodes node-1 size=Large\n</code></pre> Pod Configuration with NodeSelector (Click to Expand) <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\nspec:\n  containers:\n    - name: data-processor\n      image: data-processor\n  nodeSelector:\n    size: Large\n</code></pre> <ul> <li> <p>In the pod definition file, you can add a <code>nodeSelector</code> under the <code>spec</code> section with <code>size: large</code> to ensure the data-processing pod runs only on the larger node.  </p> </li> <li> <p>This works because nodes are assigned labels (e.g., <code>size=large</code>), and the Kubernetes scheduler matches these labels with the node selector to decide where the pod should run.</p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.04%20Node-Selectors/#node-selector-limitations","title":"Node Selector Limitations","text":"<ul> <li>NodeSelector works for simple cases with a single label.  </li> <li>Complex rules (e.g., run on <code>large OR medium</code> nodes, or avoid <code>small</code> nodes) are not possible with NodeSelector.  </li> <li>For such scenarios, use Node Affinity and Anti-Affinity.  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.05%20Node-Affinity/","title":"2.05 Node Affinity","text":"<ul> <li>Node Affinity provides advanced control over pod placement compared to NodeSelector.  </li> <li>Defined under <code>spec &gt; affinity &gt; nodeAffinity</code>.  </li> <li>Uses matchExpressions with <code>key</code>, <code>operator</code>, and <code>values</code>.  </li> <li>Example: <code>In</code>, <code>NotIn</code>, <code>Exists</code>.  </li> <li>Example rules:  </li> <li>Place pod on <code>Large</code> or <code>Medium</code> nodes.  </li> <li>Avoid scheduling on <code>Small</code> nodes.  </li> <li>Match nodes where label <code>size</code> exists.  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.05%20Node-Affinity/#node-affinity-types","title":"Node Affinity Types","text":"<ul> <li>Two stages in pod lifecycle:  </li> <li>DuringScheduling \u2013 pod creation.  </li> <li> <p>DuringExecution \u2013 pod already running.  </p> </li> <li> <p>Available Types:  </p> </li> <li><code>requiredDuringSchedulingIgnoredDuringExecution</code> \u2192 Pod scheduled only if matching node exists.  </li> <li> <p><code>preferredDuringSchedulingIgnoredDuringExecution</code> \u2192 Tries matching node, falls back to any node.  </p> </li> <li> <p>Planned Type:  </p> </li> <li><code>requiredDuringSchedulingRequiredDuringExecution</code> \u2192 Will enforce rules even after pod is running.  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.05%20Node-Affinity/#behavior-summary","title":"Behavior Summary","text":"<ul> <li>Required: Pod won\u2019t be scheduled without a matching node.  </li> <li>Preferred: Scheduler tries to match, but runs pod elsewhere if needed.  </li> <li>Ignored During Execution: Running pods are not affected if labels change later.  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.06%20Taints-and-Tolerations-vs-Node-Affinity/","title":"2.06 Taints and Tolerations vs Node Affinity","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.06%20Taints-and-Tolerations-vs-Node-Affinity/#combining-taints-tolerations-and-node-affinity","title":"Combining Taints, Tolerations, and Node Affinity","text":"<ul> <li>Use taints &amp; tolerations \u2192 block other pods from running on specific nodes.  </li> <li>Use node affinity \u2192 ensure your pods run only on the intended nodes.  </li> <li>Together, they dedicate nodes for specific workloads.  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/","title":"2.07 Resource Limits","text":"<p>In a Kubernetes cluster, each node has limited CPU and memory resources. Every pod requests specific resources, and when scheduled, it consumes them from the assigned node.  </p> <p>The Kubernetes Scheduler decides where a pod runs:</p> <ul> <li>It checks if a node has enough free resources to host the pod.  </li> <li>If a node has insufficient resources, the scheduler skips it.  </li> <li>If no node can host the pod, the pod remains in a Pending state.  </li> </ul> <p></p> <p></p> <p>You can verify this using:</p> <pre><code>kubectl describe pod &lt;pod-name&gt;\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#kubernetes-resource-units","title":"Kubernetes Resource Units","text":"<p>A single CPU unit in Kubernetes can represent:</p> <ul> <li>1 AWS vCPU</li> <li>1 GCP Core</li> <li>1 Azure Core</li> <li>1 Hyperthread</li> </ul> <p>You can request fractional CPUs as well:</p> <ul> <li><code>0.1</code> CPU = 100m (milliCPU)</li> <li>Minimum granularity is 1m.</li> <li>Example: <code>cpu: 5</code> means the container requests 5 vCPUs (if nodes have enough capacity).</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#cpu-table","title":"CPU Table","text":"Unit Equivalent 1 CPU 1 AWS vCPU / 1 GCP Core / 1 Azure Core / 1 Hyperthread 0.1 CPU 100 milliCPU (m) 1m CPU Smallest allocatable unit"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#memory-resources","title":"Memory Resources","text":"<p>Memory can be expressed using different suffixes. By default, a container has no limit and can consume all available memory on a node \u2014 potentially starving other processes. You can prevent this by setting memory limits.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#memory-table","title":"Memory Table","text":"Unit Equivalent 1G (Gigabyte) 1,000,000,000 bytes 1M (Megabyte) 1,000,000 bytes 1K (Kilobyte) 1,000 bytes 1Gi (Gibibyte) 1,073,741,824 bytes 1Mi (Mebibyte) 1,048,576 bytes 1Ki (Kibibyte) 1,024 bytes"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#example","title":"Example","text":"<ul> <li><code>memory: 256Mi</code> \u2192 256 Mebibytes  </li> <li><code>memory: 1G</code> \u2192 1,000 MB  </li> <li><code>memory: 1Gi</code> \u2192 1,024 MB  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#resource-limits","title":"Resource Limits","text":"<ul> <li>By default, containers can consume unlimited CPU/Memory from a node.  </li> <li>Requests are the minimum guaranteed resources for a container.  </li> <li><code>cpu: 2</code> \u2192 Scheduler guarantees 2 vCPUs.  </li> <li> <p><code>memory: 1Gi</code> \u2192 Scheduler guarantees 1 GiB of memory.  </p> </li> <li> <p>Limits are the maximum resources a container can use.  </p> </li> <li><code>cpu: 2</code> \u2192 Container cannot exceed 2 vCPUs.  </li> <li><code>memory: 2Gi</code> \u2192 Container cannot exceed 2 GiB of memory.  </li> </ul> Pod Resource Requests and Limits in YAML (Click to Expand) <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: simple-webapp-color\n  labels:\n    name: simple-webapp-color\nspec:\n  containers:\n    - name: simple-webapp-color\n      image: simple-webapp-color\n      ports:\n        - containerPort: 8080\n      resources:\n        requests:\n          memory: \"1Gi\"\n          cpu: 2\n        limits:\n          memory: \"2Gi\"\n          cpu: 2\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#what-happens-when-a-pod-exceeds-its-limits","title":"What Happens When a Pod Exceeds Its Limits?","text":"<ul> <li> <p>CPU:   If a pod tries to use more CPU than its limit, the system will throttle it.   The container cannot exceed the defined CPU limit.</p> </li> <li> <p>Memory:   Memory works differently. A container can attempt to use more memory than its limit,   but if it consistently exceeds that value, the pod will be terminated.   You\u2019ll see the termination reason as OOMKilled (Out of Memory) in logs or in   the output of <code>kubectl describe pod</code>.</p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#behavior-of-cpu-requests-and-limits","title":"Behavior of CPU Requests and Limits","text":"<p>By default, Kubernetes does not define CPU or memory requests or limits. This means any pod can consume as many resources as it wants, potentially starving other pods or system processes. Let\u2019s examine different scenarios with two pods competing for CPU:</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#cpu-requests-and-limits-behavior","title":"CPU Requests and Limits Behavior","text":"Scenario Requests Limits Behavior Notes / Best Practice 1. No Requests, No Limits \u274c None \u274c None Pods can consume unlimited CPU. One pod may take all resources and starve others. \u26a0\ufe0f Not recommended 2. No Requests, With Limits \u274c None \u2705 Set Kubernetes assumes requests = limits. Example: if limit = 3 vCPUs, pod gets exactly 3 vCPUs. Can waste CPU if other pods are idle 3. Requests + Limits \u2705 Set \u2705 Set Pod is guaranteed requests (e.g., 1 vCPU) and can scale up to the defined limit (e.g., 3 vCPUs). Fair, but can block a pod from using extra unused CPU 4. Requests Only (No Limits) \u2705 Set \u274c None Each pod gets guaranteed CPU (e.g., 1 vCPU) but can use more if available. Other pods are still guaranteed their requests. \u2705 Recommended setup (flexible + fair)"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#key-notes","title":"Key Notes","text":"<ul> <li>By default, Kubernetes sets no requests and no limits.  </li> <li>Always define requests to guarantee minimum resources for each pod.  </li> <li>Use limits only when you need to strictly control resource usage (e.g., shared/public clusters).  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#_1","title":"2.07 Resource Limits","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#when-to-use-limits","title":"When to Use Limits","text":"<ul> <li>In some environments (e.g., shared clusters or public labs), limits are required to prevent misuse.   Example: restricting containers from excessive workloads like crypto mining.  </li> <li>For applications you control, consider setting requests but leaving limits unset for better resource utilization.  </li> <li>Always ensure every pod has requests defined \u2014 otherwise, it risks being starved when competing pods consume all available resources.</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#behavior-of-memory-requests-and-limits","title":"Behavior of Memory Requests and Limits","text":"<p>Unlike CPU (which can be throttled), memory cannot be throttled. If a pod exceeds its memory limit, it is killed (OOMKilled) and restarted.  </p> Scenario Requests Limits Behavior Notes 1. No Requests, No Limits \u274c None \u274c None One pod can consume all memory and starve others. \u26a0\ufe0f Not recommended 2. No Requests, With Limits \u274c None \u2705 Set Kubernetes assumes requests = limits. Example: 3Gi request &amp; limit. Guarantees memory but can waste unused capacity 3. Requests + Limits \u2705 Set \u2705 Set Example: <code>requests = 1Gi</code>, <code>limits = 3Gi</code>. Pod is guaranteed 1Gi and capped at 3Gi. Fair sharing, but strict cap may block efficient usage 4. Requests Only (No Limits) \u2705 Set \u274c None Example: <code>requests = 1Gi</code>, no limits. Pod can use all available memory. If it exceeds node capacity, it will be killed. \u2705 Useful for flexibility, but risky since OOMKill occurs <p></p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#default-resource-policies-limitranges","title":"Default Resource Policies (LimitRanges)","text":"<ul> <li> <p>By default, pods have no requests or limits. To enforce defaults at the namespace level, Kubernetes provides LimitRanges.</p> </li> <li> <p>A <code>LimitRange</code> object defines:   default requests/limits (applied if not set in pod spec)</p> </li> </ul> CPU LimitRange (Click to Expand) <pre><code>apiVersion: v1\nkind: LimitRange\nmetadata:\n  name: cpu-resource-constraint\nspec:\n  limits:\n    - default:\n        cpu: 500m\n      defaultRequest:\n        cpu: 500m\n      max:\n        cpu: \"1\"\n      min:\n        cpu: 100m\n      type: Container\n</code></pre> Memory LimitRange (Click to Expand) <pre><code>apiVersion: v1\nkind: LimitRange\nmetadata:\n  name: memory-resource-constraint\nspec:\n  limits:\n    - default:\n        memory: 1Gi\n      defaultRequest:\n        memory: 1Gi\n      max:\n        memory: 1Gi\n      min:\n        memory: 500Mi\n      type: Container\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#limitrange-explanation","title":"LimitRange Explanation","text":"Field CPU Example Memory Example Meaning default <code>500m</code> <code>1Gi</code> Default limit if none is specified in the pod/container spec defaultRequest <code>500m</code> <code>1Gi</code> Default request if none is specified in the pod/container spec max <code>1</code> (1 vCPU) <code>1Gi</code> Maximum value a container can request min <code>100m</code> (0.1 vCPU) <code>500Mi</code> Minimum value a container must request type <code>Container</code> <code>Container</code> Applies the LimitRange at the container level"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#key-notes_1","title":"Key Notes","text":"<ul> <li>LimitRange applies at the namespace level.  </li> <li>It only affects newly created pods (existing pods are unaffected).  </li> <li>Ensures fair resource allocation and prevents abuse (e.g., setting extremely high requests).  </li> <li>Values shown here are examples, not strict recommendations \u2014 adjust based on your application needs.  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#resource-quotas-in-kubernetes","title":"Resource Quotas in Kubernetes","text":"<p>To restrict the total amount of resources consumed by applications in a Kubernetes cluster,  you can define ResourceQuotas at the namespace level.  </p> <p>A ResourceQuota sets hard limits on the total amount of CPU and memory that all pods in a namespace can request or consume.  </p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.07%20Resource-Limits/#example-explanation","title":"Example Explanation","text":"<ul> <li>requests.cpu: 4 \u2192 All pods in this namespace together can request up to 4 CPUs.  </li> <li>requests.memory: 4Gi \u2192 All pods can request up to 4 GiB of memory.  </li> <li>limits.cpu: 10 \u2192 Maximum CPU usage across all pods is 10 CPUs.  </li> <li>limits.memory: 10Gi \u2192 Maximum memory usage across all pods is 10 GiB.  </li> </ul> ResourceQuota Example in YAML (Click to Expand) <pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: my-resource-quota\nspec:\n  hard:\n    requests.cpu: 4\n    requests.memory: 4Gi\n    limits.cpu: 10\n    limits.memory: 10Gi\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.08%20DaemonSets/","title":"2.08 DaemonSets","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.08%20DaemonSets/#daemonsets-in-kubernetes","title":"\ud83e\udde9 DaemonSets in Kubernetes","text":"<ul> <li>DaemonSets are similar to ReplicaSets, but instead of managing replicas across nodes, they ensure one pod runs on every node in the cluster.  </li> <li>When a new node joins, a pod is automatically created on it; when a node is removed, the corresponding pod is deleted.  </li> <li>This guarantees one instance per node, maintaining consistent functionality across the cluster.  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.08%20DaemonSets/#use-cases","title":"\ud83d\udd39 Use Cases","text":"<ul> <li>Deploying monitoring agents (e.g., Prometheus Node Exporter).  </li> <li>Running log collectors (e.g., Fluentd, Filebeat).  </li> <li>Installing node-level system daemons such as storage or networking agents.  </li> <li>Deploying networking components like Calico, which requires an agent on each node.  </li> <li>Running kube-proxy, which can be deployed as a DaemonSet to manage networking rules on all nodes.  </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.08%20DaemonSets/#key-points","title":"\ud83d\udd39 Key Points","text":"<ul> <li>The DaemonSet manifest is almost identical to a ReplicaSet\u2019s, except:</li> <li><code>apiVersion</code> \u2192 <code>apps/v1</code></li> <li><code>kind</code> \u2192 <code>DaemonSet</code></li> <li>Includes a <code>selector</code> and <code>template</code> section with matching labels </li> <li>To create and inspect a DaemonSet:   <pre><code>kubectl create -f daemonset-definition.yaml\nkubectl get daemonsets\nkubectl describe daemonset &lt;name&gt;\n</code></pre></li> </ul> <p>Below is a sample YAML definition for a simple monitoring DaemonSet.</p> \ud83e\uddfe DaemonSet Example (Click to Expand) <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: monitoring-daemon\n  labels:\n    app: monitor-agent\nspec:\n  selector:\n    matchLabels:\n      app: monitor-agent\n  template:\n    metadata:\n      labels:\n        app: monitor-agent\n    spec:\n      containers:\n        - name: node-monitor\n          image: busybox\n          imagePullPolicy: IfNotPresent\n          command: [\"sh\", \"-c\", \"while true; do echo 'Monitoring node...'; sleep 30; done\"]\n          resources:\n            limits:\n              cpu: \"100m\"\n              memory: \"128Mi\"\n            requests:\n              cpu: \"50m\"\n              memory: \"64Mi\"\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.08%20DaemonSets/#daemonsets-video-tutorial","title":"\ud83c\udfa5 DaemonSets Video Tutorial","text":"<p>Watch this video to understand DaemonSets in Kubernetes more visually:</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.09%20Static-Pods/","title":"2.09 Static Pods","text":"<p>Static Pods are pods managed directly by the kubelet, independent of the kube-apiserver or other control plane components.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.09%20Static-Pods/#key-concept","title":"Key Concept","text":"<ul> <li>Normally, the kubelet relies on the kube-apiserver and scheduler for instructions.  </li> <li>However, even without these components (no master, etcd, or controllers), the kubelet can operate independently by creating pods from manifest files placed in a designated directory on the node.</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.09%20Static-Pods/#how-it-works","title":"How It Works","text":"<ul> <li>The kubelet periodically checks a configured Pod Manifest Path (e.g., <code>/etc/kubernetes/manifests</code>) for pod definition files.  </li> <li>When a file is added \u2192 the kubelet creates the pod.  </li> <li>When the file is updated \u2192 the kubelet recreates the pod.  </li> <li>When the file is removed \u2192 the pod is automatically deleted.  </li> <li>The kubelet ensures the pod stays running and restarts it if it crashes.</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.09%20Static-Pods/#configuration-options","title":"Configuration Options","text":"<p>You can configure the static pod path in two ways:</p> <ol> <li> <p>Directly in the kubelet service: <pre><code>--pod-manifest-path=/etc/kubernetes/manifests\n</code></pre> </p> </li> <li> <p>Through the Kubelet Config File: <pre><code>staticPodPath: /etc/kubernetes/manifests\n</code></pre> The kubelet continuously monitors this directory and manages any pod definitions within it. </p> </li> </ol>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.09%20Static-Pods/#commands","title":"Commands","text":"<ul> <li> <p>When working outside a cluster (no API server), view static pods using CRI commands: <pre><code>  docker ps \n</code></pre></p> </li> <li> <p>When the node is part of a cluster, view static pods as mirror pods in the API server: <pre><code>kubectl get pods\n</code></pre></p> </li> <li> <p>Static pods appear as read-only mirror pods in the API server.  </p> </li> <li>Their names are automatically appended with the node name,      </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.09%20Static-Pods/#kubelet-and-static-pod-interaction","title":"\ud83d\udd39 Kubelet and Static Pod Interaction","text":"<p>The kubelet can receive instructions to create pods from two different sources:</p> <ul> <li>From pod definition files located in the static pod directory.  </li> <li> <p>From HTTP API requests sent by the kube-apiserver.</p> </li> <li> <p>This allows the kubelet to manage both static pods and regular pods at the same time.</p> </li> <li> <p>When a node running the kubelet is part of a cluster, the API server becomes aware of the static pods it creates.  </p> </li> <li> <p>The kubelet automatically generates a mirror object for each static pod within the API server.</p> </li> <li> <p>These mirror pods appear like regular pods in the cluster, but they are read-only representations.  </p> </li> <li>You can view their details, but you cannot edit or delete them through the API server.  </li> <li>To modify or remove a static pod, you must update or delete its manifest file from the node\u2019s designated manifest directory.</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.09%20Static-Pods/#use-case","title":"\ud83d\udd39 Use Case","text":"<p>Static Pods are ideal for deploying control plane components, such as:</p> <ul> <li><code>kube-apiserver</code></li> <li><code>kube-controller-manager</code></li> <li><code>etcd</code></li> </ul> <p></p> <ul> <li>They restart automatically if they crash, making them reliable for bootstrapping clusters.  </li> <li>This is exactly how kubeadm sets up the control plane \u2014 by running its core components as static pods stored under <code>/etc/kubernetes/manifests</code>.</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.09%20Static-Pods/#static-pods-vs-daemonsets","title":"\ud83d\udd39 Static Pods vs DaemonSets","text":"Static Pods DaemonSets Created by the kubelet Created by the kube-apiserver (DaemonSet Controller) Deploy Control Plane components as static pods Deploy Monitoring Agents or Logging Agents on all nodes Ignored by the kube-scheduler Ignored by the kube-scheduler"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.10%20Priority-Classes/","title":"2.10 Priority Classes","text":"<ul> <li>Kubernetes allows running workloads (pods) with different priorities to ensure that critical applications always get the resources they need.  </li> <li>For example, Kubernetes control plane components must always run, even if lower-priority applications need to be terminated.</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.10%20Priority-Classes/#what-are-priority-classes","title":"\ud83d\udd39 What Are Priority Classes?","text":"<p>Priority Classes define the scheduling importance of workloads in Kubernetes. They determine which pods get scheduled first and which can be preempted (evicted) when resources are scarce.</p> <ul> <li>Higher priority workloads are scheduled before lower priority ones.  </li> <li>If necessary, lower-priority pods may be terminated to make room for higher-priority pods.  </li> <li>Priority Classes are non-namespaced objects, meaning they are available cluster-wide and can be applied to pods in any namespace.</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.10%20Priority-Classes/#priority-range","title":"\ud83d\udd39 Priority Range","text":"<ul> <li>Priority values are represented as integers.</li> <li>The general range for user workloads is between -2,000,000,000 and +1,000,000,000.  </li> <li>Higher numbers represent higher priority.  </li> <li>Kubernetes system-critical components (like control plane pods) use values up to 2,000,000,000, ensuring they are never preempted by regular workloads.</li> </ul> \ud83e\uddfe PriorityClass Definition (Click to Expand) <pre><code>apiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: high-priority\nvalue: 1000000000\ndescription: \"Priority class for mission-critical pods\"\n</code></pre> \ud83e\udde9 Pod Using PriorityClass (Click to Expand) <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n    - name: nginx\n      image: nginx\n      ports:\n        - containerPort: 8080\n  priorityClassName: high-priority\n</code></pre> \u2699\ufe0f Default PriorityClass (Click to Expand) <pre><code>apiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: default-priority\nvalue: 1000\nglobalDefault: true\ndescription: \"Default priority for pods without explicit priority class\"\n</code></pre> \ud83d\udeab Non-Preempting PriorityClass (Click to Expand) <pre><code>apiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: non-preempting\nvalue: 600000000\npreemptionPolicy: Never\ndescription: \"Non-preempting priority class that waits for resources\"\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.10%20Priority-Classes/#default-priorityclass-vs-non-preempting-priorityclass","title":"\ud83d\udd39 Default PriorityClass vs Non-Preempting PriorityClass","text":"Feature Default PriorityClass Non-Preempting PriorityClass Purpose Defines the default priority for pods that don\u2019t specify a <code>priorityClassName</code>. Prevents pods from evicting existing lower-priority pods. Key Field <code>globalDefault: true</code> <code>preemptionPolicy: Never</code> Effect on Pods All pods without a defined priority class will automatically use this class. Pods will wait in the scheduling queue until resources are available instead of preempting others. Preemption Behavior Can preempt lower-priority pods (default Kubernetes behavior). Will not preempt any running pods, even if higher in priority. Number Allowed Only one Default PriorityClass is allowed per cluster. You can create multiple Non-Preempting PriorityClasses. Use Case When you want to assign a baseline priority to all workloads. When you want critical pods to have priority in scheduling but avoid disrupting running workloads."},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/","title":"2.11 Multiple Schedulers","text":"<ul> <li> <p>Kubernetes uses a default scheduler to assign Pods to nodes based on resource availability, taints/tolerations, affinity rules, and placement constraints.</p> </li> <li> <p>For advanced scenarios, Kubernetes is extensible and allows you to run custom schedulers with your own placement logic.</p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#when-to-use-a-custom-scheduler","title":"When to Use a Custom Scheduler","text":"<p>Use a custom scheduler only when default scheduling behavior is not sufficient.</p> <p>You may need one when:</p> <ul> <li>Custom scheduling algorithms are required</li> <li>Additional placement validation is needed</li> <li>Special node selection rules must be enforced</li> <li>Certain workloads require dedicated scheduling behavior</li> </ul> <p>Tip</p> <p>Most workloads should continue using the default scheduler.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#multiple-scheduler-support","title":"Multiple Scheduler Support","text":"<p>Kubernetes supports multiple schedulers running simultaneously.</p> <ul> <li>Default scheduler handles regular Pods</li> <li>Custom schedulers handle only Pods that reference them</li> <li>Custom schedulers are typically deployed as Pods</li> <li>They can run alongside the default scheduler</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#scheduler-naming","title":"Scheduler Naming","text":"<p>Each scheduler must have a unique name.</p> Item Value Default scheduler name <code>default-scheduler</code> Defined in Scheduler configuration file Pod field <code>schedulerName</code> If not specified Default scheduler is used"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#scheduler-configuration","title":"Scheduler Configuration","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#default-scheduler","title":"Default Scheduler","text":"<pre><code>apiVersion: kubescheduler.config.k8s.io/v1\nkind: KubeSchedulerConfiguration\nprofiles:\n  - schedulerName: default-scheduler\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#custom-scheduler","title":"Custom Scheduler","text":"<pre><code>apiVersion: kubescheduler.config.k8s.io/v1\nkind: KubeSchedulerConfiguration\nprofiles:\n  - schedulerName: my-scheduler\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#pod-using-a-custom-scheduler","title":"Pod Using a Custom Scheduler","text":"<p>A Pod selects a scheduler using the <code>schedulerName</code> field.</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: custom-scheduled-pod\nspec:\n  schedulerName: my-scheduler\n  containers:\n    - name: nginx\n      image: nginx\n</code></pre> <p>Only Pods that specify this field will be handled by the custom scheduler.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#deploying-a-custom-scheduler-kubeadm","title":"Deploying a Custom Scheduler (kubeadm)","text":"<p>In kubeadm clusters, control plane components run as Pods. You can deploy an additional scheduler as a Pod running the <code>kube-scheduler</code> binary.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#required-arguments","title":"Required Arguments","text":"Flag Purpose <code>--kubeconfig</code> API server authentication <code>--config</code> Scheduler configuration file"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#custom-scheduler-pod-example","title":"Custom Scheduler Pod Example","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-custom-scheduler\n  namespace: kube-system\nspec:\n  containers:\n    - name: kube-scheduler\n      image: k8s.gcr.io/kube-scheduler-amd64:v1.xx.x\n      command:\n        - kube-scheduler\n        - --address=127.0.0.1\n        - --kubeconfig=/etc/kubernetes/scheduler.conf\n        - --config=/etc/kubernetes/my-scheduler-config.yaml\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#leader-election-ha-clusters","title":"Leader Election (HA Clusters)","text":"<p>Leader election is required when running scheduler replicas across multiple control-plane nodes.</p> <p>Warning</p> <p>Without leader election, multiple schedulers may try to schedule the same Pod.</p> <pre><code>apiVersion: kubescheduler.config.k8s.io/v1\nkind: KubeSchedulerConfiguration\nprofiles:\n  - schedulerName: my-scheduler\n\nleaderElection:\n  leaderElect: true\n  resourceNamespace: kube-system\n  resourceName: lock-object-my-scheduler\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#troubleshooting-custom-scheduler-issues","title":"Troubleshooting Custom Scheduler Issues","text":"<p>If a custom scheduler is not running or misconfigured, Pods using it will remain in Pending state.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#check-pod-scheduling-details","title":"Check Pod Scheduling Details","text":"<pre><code>kubectl describe pod &lt;pod-name&gt;\n</code></pre> <p>Check the Events section for scheduling errors.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#identify-which-scheduler-scheduled-a-pod","title":"Identify Which Scheduler Scheduled a Pod","text":"<pre><code>kubectl get events -o wide\n</code></pre> <p>Look for:</p> <ul> <li>Reason = <code>Scheduled</code></li> <li>Source column = scheduler name</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#check-scheduler-logs","title":"Check Scheduler Logs","text":"Scheduler PodScheduler Deployment <pre><code>kubectl logs &lt;scheduler-pod-name&gt; -n kube-system\n</code></pre> <pre><code>kubectl logs deploy/&lt;scheduler-deployment-name&gt; -n kube-system\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#command-reference","title":"Command Reference","text":"<pre><code>kubectl describe pod &lt;pod-name&gt;\nkubectl get events -o wide\nkubectl logs &lt;scheduler-pod-name&gt; -n kube-system\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.11%20Multiple-Schedulers/#summary","title":"Summary","text":"<ul> <li>Default scheduler handles most workloads</li> <li>Custom schedulers support specialized placement logic</li> <li>Multiple schedulers can run together</li> <li>Each scheduler requires a unique name</li> <li>Pods select schedulers using <code>schedulerName</code></li> <li>Enable leader election in HA setups</li> <li>Use describe, events, and logs for troubleshooting</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.12%20configuring-scheduler-profiles/","title":"2.12 Configuring Scheduler Profiles","text":"<p>Kubernetes Scheduler Profiles let you run multiple logical schedulers inside a single scheduler binary. Each profile behaves like an independent scheduler but shares the same process \u2014 reducing operational overhead and avoiding race conditions between multiple scheduler instances.</p> <p>Info</p> <p>Scheduler Profiles were introduced in Kubernetes v1.18+.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.12%20configuring-scheduler-profiles/#why-scheduler-profiles","title":"Why Scheduler Profiles","text":"<p>Before Scheduler Profiles, running multiple schedulers required:</p> <ul> <li>Separate scheduler binaries</li> <li>Separate configuration files</li> <li>Separate running processes</li> </ul> <p>This led to:</p> <ul> <li>Higher maintenance overhead</li> <li>More resource usage</li> <li>Possible race conditions between schedulers</li> </ul> <p>Note</p> <p>Scheduler Profiles allow multiple scheduler behaviors inside one scheduler process instead of running multiple scheduler services.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.12%20configuring-scheduler-profiles/#what-is-a-scheduler-profile","title":"What Is a Scheduler Profile","text":"<p>A Scheduler Profile is a configuration block inside the scheduler configuration file that defines:</p> <ul> <li>A unique scheduler name</li> <li>Plugin configuration</li> <li>Extension point behavior</li> </ul> <p>Each profile:</p> <ul> <li>Acts like a separate logical scheduler</li> <li>Uses the same <code>kube-scheduler</code> binary</li> <li>Can behave differently through plugin settings</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.12%20configuring-scheduler-profiles/#how-pods-choose-a-scheduler-profile","title":"How Pods Choose a Scheduler Profile","text":"<p>Pods select which scheduler profile to use with the <code>schedulerName</code> field.</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: example-pod\nspec:\n  schedulerName: my-scheduler-2\n  containers:\n    - name: nginx\n      image: nginx\n</code></pre> <p>If <code>schedulerName</code> is not specified, the default profile (<code>default-scheduler</code>) is used.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.12%20configuring-scheduler-profiles/#scheduler-profiles-concept-diagram","title":"Scheduler Profiles \u2014 Concept Diagram","text":"<pre><code>                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502        kube-scheduler        \u2502\n                    \u2502        (single binary)       \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                          \u2502                          \u2502\n        \u25bc                          \u25bc                          \u25bc\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Profile A        \u2502     \u2502 Profile B        \u2502     \u2502 Profile C        \u2502\n\u2502 schedulerName:   \u2502     \u2502 schedulerName:   \u2502     \u2502 schedulerName:   \u2502\n\u2502 default-scheduler\u2502     \u2502 my-scheduler-2   \u2502     \u2502 my-scheduler-3   \u2502\n\u2502                  \u2502     \u2502                  \u2502     \u2502                  \u2502\n\u2502 Default plugins  \u2502     \u2502 Custom plugins   \u2502     \u2502 Scoring disabled \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n        \u2502                          \u2502                          \u2502\n        \u25bc                          \u25bc                          \u25bc\n\n Pods without              Pods with                   Pods with\n schedulerName      schedulerName=my-scheduler-2  schedulerName=my-scheduler-3\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.12%20configuring-scheduler-profiles/#configuring-multiple-profiles","title":"Configuring Multiple Profiles","text":"<p>Multiple profiles are defined under the <code>profiles</code> section in the scheduler configuration.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.12%20configuring-scheduler-profiles/#example-configuration","title":"Example Configuration","text":"<pre><code>apiVersion: kubescheduler.config.k8s.io/v1\nkind: KubeSchedulerConfiguration\n\nprofiles:\n\n  - schedulerName: my-scheduler-2\n    plugins:\n      score:\n        disabled:\n          - name: TaintToleration\n        enabled:\n          - name: MyCustomPluginA\n          - name: MyCustomPluginB\n\n  - schedulerName: my-scheduler-3\n    plugins:\n      preScore:\n        disabled:\n          - name: \"*\"\n      score:\n        disabled:\n          - name: \"*\"\n\n  - schedulerName: my-scheduler-4\n</code></pre> <p>Tip</p> <p>Each profile can enable or disable plugins independently to change scheduling behavior.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.12%20configuring-scheduler-profiles/#scheduler-extension-points","title":"Scheduler Extension Points","text":"<p>Scheduler plugins run at different extension points during the scheduling cycle.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.12%20configuring-scheduler-profiles/#scheduling-flow-diagram","title":"Scheduling Flow Diagram","text":"<pre><code>Pod Enters Queue\n      \u2502\n      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Queue Sort   \u2502  \u2192 Example: PrioritySort\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Filtering    \u2502  \u2192 NodeResourcesFit, NodeAffinity, TaintToleration\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Scoring      \u2502  \u2192 ImageLocality, NodeResourcesFit\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Binding      \u2502  \u2192 DefaultBinder\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.12%20configuring-scheduler-profiles/#major-extension-points","title":"Major Extension Points","text":"QueueFilteringScoringBinding <ul> <li><code>queueSort</code></li> <li>Controls Pod ordering</li> <li>Example: PrioritySort</li> </ul> <ul> <li><code>preFilter</code>, <code>filter</code>, <code>postFilter</code></li> <li>Removes unsuitable nodes</li> <li>Examples: NodeResourcesFit, NodeAffinity, TaintToleration</li> </ul> <ul> <li><code>preScore</code>, <code>score</code>, <code>reserve</code></li> <li>Ranks remaining nodes</li> <li>Examples: ImageLocality, NodeResourcesFit</li> </ul> <ul> <li><code>permit</code>, <code>preBind</code>, <code>bind</code>, <code>postBind</code></li> <li>Final node assignment</li> <li>Example: DefaultBinder</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.12%20configuring-scheduler-profiles/#plugin-customization-per-profile","title":"Plugin Customization Per Profile","text":"<p>Each scheduler profile can customize plugins independently.</p> <p>You can:</p> <ul> <li>Enable specific plugins</li> <li>Disable specific plugins</li> <li>Disable all plugins using <code>\"*\"</code></li> <li>Use custom plugins</li> <li>Change filtering and scoring behavior</li> </ul> <p>Tip</p> <p>Profiles mainly differ by plugin configuration, not just scheduler name.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.12%20configuring-scheduler-profiles/#key-takeaways","title":"Key Takeaways","text":"<p>Summary</p> <ul> <li>Scheduler Profiles run multiple logical schedulers in one binary</li> <li>Each profile has a unique <code>schedulerName</code></li> <li>Pods select profiles using <code>schedulerName</code></li> <li>Profiles customize plugin behavior</li> <li>Reduces operational overhead</li> <li>Avoids multi-scheduler race conditions</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/","title":"2.13 Admission Controllers","text":"<p>Admission Controllers are policy enforcement components inside the Kubernetes API server. They intercept every request after Authentication and Authorization and before the object is created in the cluster.</p> <p>They help you validate, modify, and enforce security rules on resources like Pods, Namespaces, and PVCs.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#where-admission-controllers-fit-in-the-request-flow","title":"\ud83d\udd10 Where Admission Controllers Fit in the Request Flow","text":"<p>When you run a command such as:</p> <pre><code>kubectl run nginx --image=nginx\n</code></pre> <p>The request flows through these stages:</p> <ol> <li>Authentication \u2014 Who is making the request?</li> <li>Authorization (RBAC) \u2014 Is the user allowed to do this action?</li> <li>Admission Controllers \u2014 Should this request be accepted, rejected, or modified?</li> <li>etcd \u2014 Object is stored if approved</li> </ol> <p>Info</p> <p>Admission Controllers are the final checkpoint before a resource is created.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#why-admission-controllers-are-needed","title":"\ud83c\udfaf Why Admission Controllers Are Needed","text":"<p>RBAC controls who can do what \u2014 but not how resources are configured.</p> <p>RBAC can control:</p> <ul> <li>Who can create Pods</li> <li>Who can delete Deployments</li> <li>Namespace-level permissions</li> <li>Specific resource names</li> </ul> <p>RBAC cannot enforce rules like:</p> <ul> <li>Only allow images from internal registry</li> <li>Block containers running as root</li> <li>Disallow <code>latest</code> image tag</li> <li>Require labels on all Pods</li> <li>Restrict Linux capabilities</li> </ul> <p>Note</p> <p>Admission Controllers enforce configuration and security policies beyond simple access control.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#what-admission-controllers-can-do","title":"\ud83e\udde9 What Admission Controllers Can Do","text":"<p>Admission Controllers can:</p> <ul> <li>\u2705 Reject invalid or unsafe requests</li> <li>\u2705 Modify objects before creation (mutation)</li> <li>\u2705 Inject default values</li> <li>\u2705 Enforce cluster security standards</li> <li>\u2705 Trigger additional checks</li> </ul> <p>They work automatically once enabled in kube-apiserver.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#common-builtin-admission-controllers","title":"\ud83d\udce6 Common Built\u2011in Admission Controllers","text":"Controller What It Does AlwaysPullImages Forces image pull every time a Pod starts DefaultStorageClass Adds default storage class to PVCs LimitRanger Applies default CPU/memory limits ResourceQuota Enforces namespace quotas NamespaceLifecycle Protects and validates namespaces EventRateLimit Limits API request bursts <p>Tip</p> <p>Most production clusters keep several admission controllers enabled by default.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#rbac-yaml-example-authorization","title":"\ud83e\uddfe RBAC YAML Example (Authorization)","text":"<p>RBAC decides whether a user/service account is allowed to perform an action.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#role-allow-pod-operations-in-a-namespace","title":"Role (Allow Pod Operations in a Namespace)","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: developer\n  namespace: dev\nrules:\n  - apiGroups: [\"\"]\n    resources: [\"pods\"]\n    verbs: [\"get\", \"list\", \"create\", \"update\", \"delete\"]\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#rolebinding-attach-role-to-a-user-or-serviceaccount","title":"RoleBinding (Attach Role to a User or ServiceAccount)","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: developer-binding\n  namespace: dev\nsubjects:\n  - kind: User\n    name: john\n    apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: developer\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <p>Note</p> <p>RBAC can allow or deny API actions, but it does not validate Pod configuration (image, tags, runAsRoot, etc.).</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#example-namespace-validation-check","title":"\ud83e\uddea Example \u2014 Namespace Validation Check","text":"<p>Try creating a Pod in a namespace that does not exist:</p> <pre><code>kubectl run nginx --image=nginx -n blue\n</code></pre> <p>Output:</p> <pre><code>Error: namespace \"blue\" not found\n</code></pre> <p>What happened:</p> <ul> <li>Authentication \u2192 \u2705 passed  </li> <li>Authorization \u2192 \u2705 passed  </li> <li>Admission Controller \u2192 \u274c rejected (NamespaceLifecycle)</li> </ul> <p>Example</p> <p>The NamespaceLifecycle controller blocks requests to non\u2011existent namespaces.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#admission-policy-yaml-examples-better-understanding","title":"\ud83d\udee1\ufe0f Admission Policy YAML Examples (Better Understanding)","text":"<p>Admission Controllers can be built-in (enabled on kube-apiserver) or implemented using policies.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#example-1-validate-pod-configuration-kyverno-policy","title":"Example 1 \u2014 Validate Pod Configuration (Kyverno Policy)","text":"<p>This example blocks Pods that use the <code>latest</code> tag.</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: disallow-latest-tag\nspec:\n  validationFailureAction: Enforce\n  rules:\n    - name: no-latest-tag\n      match:\n        resources:\n          kinds:\n            - Pod\n      validate:\n        message: \"Using the 'latest' tag is not allowed.\"\n        pattern:\n          spec:\n            containers:\n              - image: \"!*:latest\"\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#example-2-enforce-labels-on-pods-kyverno-policy","title":"Example 2 \u2014 Enforce Labels on Pods (Kyverno Policy)","text":"<pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: require-app-label\nspec:\n  validationFailureAction: Enforce\n  rules:\n    - name: check-app-label\n      match:\n        resources:\n          kinds:\n            - Pod\n      validate:\n        message: \"Pods must have the label: app\"\n        pattern:\n          metadata:\n            labels:\n              app: \"?*\"\n</code></pre> <p>Tip</p> <p>These policies demonstrate what Admission Controllers are meant to enforce: resource configuration rules.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#auto-namespace-creation-if-plugin-enabled","title":"\u2699\ufe0f Auto Namespace Creation (If Plugin Enabled)","text":"<p>Some clusters enable auto\u2011provision behavior:</p> <ul> <li>Namespace does not exist</li> <li>Admission plugin creates namespace</li> <li>Pod creation continues</li> </ul> <p>Warning</p> <p>Old plugin <code>NamespaceAutoProvision</code> is deprecated. Modern clusters use NamespaceLifecycle instead.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#view-enabled-admission-controllers","title":"\ud83d\udd0d View Enabled Admission Controllers","text":"<p>Check enabled plugins on the API server:</p> <pre><code>kube-apiserver -h | grep enable-admission-plugins\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#kubeadm-clusters","title":"kubeadm Clusters","text":"<pre><code>kubectl exec -n kube-system kube-apiserver-&lt;node&gt; -- \\\nkube-apiserver -h | grep enable-admission-plugins\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#enable-admission-controllers","title":"\u2795 Enable Admission Controllers","text":"<p>Edit kube-apiserver manifest:</p> <pre><code>/etc/kubernetes/manifests/kube-apiserver.yaml\n</code></pre> <p>Add flag:</p> <pre><code>--enable-admission-plugins=NodeRestriction,NamespaceLifecycle\n</code></pre> <p>Kubernetes will restart the API server automatically (static pod).</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#disable-admission-controllers","title":"\u2796 Disable Admission Controllers","text":"<pre><code>--disable-admission-plugins=DefaultStorageClass\n</code></pre> <p>Danger</p> <p>Disabling critical admission controllers can weaken cluster security and policy enforcement.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#validating-vs-mutating-controllers","title":"\ud83e\udde0 Validating vs Mutating Controllers","text":"Validating ControllersMutating Controllers <ul> <li>Only approve or reject</li> <li>Do not change the object</li> <li>Policy gate only</li> <li>Example: NamespaceLifecycle</li> </ul> <ul> <li>Modify objects before creation</li> <li>Add defaults or fields</li> <li>Adjust configuration automatically</li> <li>Example: DefaultStorageClass</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#simple-admission-stage-diagram","title":"\ud83d\uddbc\ufe0f Simple Admission Stage Diagram","text":"<pre><code>kubectl request\n      \u2193\nAPI Server\n  \u2192 Authentication\n  \u2192 Authorization\n  \u2192 Admission Controllers\n  \u2192 etcd store\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.13%20Admission-Controllers/#key-takeaways","title":"\u2705 Key Takeaways","text":"<p>Summary</p> <ul> <li>Admission Controllers run after authN and authZ</li> <li>They enforce configuration and security rules</li> <li>They can reject or modify requests</li> <li>RBAC = who can act</li> <li>Admission = how objects must look</li> <li>Configured via kube-apiserver flags</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/","title":"2.14 Validating and Mutating Admission Controllers","text":"<p>Admission Controllers are policy checkpoints inside the Kubernetes API server. They run after Authentication and Authorization and before an object is finally created.</p> <p>Their job is simple:</p> <ul> <li>\u2705 Mutating controllers \u2192 can CHANGE the request  </li> <li>\ud83d\udee1\ufe0f Validating controllers \u2192 can ALLOW or REJECT the request  </li> </ul> <p>Think of them as a final quality + security gate for every Kubernetes object.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#where-they-sit-in-the-request-flow","title":"\ud83d\udd04 Where They Sit in the Request Flow","text":"<p>When you run:</p> <pre><code>kubectl apply -f pod.yaml\n</code></pre> <p>The API server processes it in this order:</p> <ol> <li>Authentication \u2014 Who are you?</li> <li>Authorization (RBAC) \u2014 Are you allowed?</li> <li>Mutating Admission Controllers \u2014 Modify request if needed</li> <li>Validating Admission Controllers \u2014 Approve or reject</li> <li>etcd \u2014 Object stored</li> </ol> <p>Info</p> <p>Mutation happens first, then validation checks the final modified object.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#two-types-quick-comparison","title":"\ud83e\uddea Two Types \u2014 Quick Comparison","text":"\ud83e\uddec Mutating Admission Controllers\ud83d\udee1\ufe0f Validating Admission Controllers <ul> <li>Can modify objects</li> <li>Add missing fields</li> <li>Inject defaults</li> <li>Add labels / sidecars</li> <li>Runs first</li> <li>Example: DefaultStorageClass</li> </ul> <ul> <li>Cannot modify objects</li> <li>Only allow or reject</li> <li>Enforce rules</li> <li>Block unsafe configs</li> <li>Runs after mutation</li> <li>Example: NamespaceLifecycle</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#mutating-admission-controllers-easy-example","title":"\ud83e\uddec Mutating Admission Controllers \u2014 Easy Example","text":"<p>A mutating controller can auto\u2011fill missing fields.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#example-defaultstorageclass","title":"Example: DefaultStorageClass","text":"<p>You create a PVC without storageClassName:</p> <pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: data-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n</code></pre> <p>Mutating controller updates it internally to:</p> <pre><code>spec:\n  storageClassName: standard\n</code></pre> <p>Example</p> <p>You didn\u2019t specify it \u2014 Kubernetes adds it automatically using a mutating controller.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#validating-admission-controllers-easy-example","title":"\ud83d\udee1\ufe0f Validating Admission Controllers \u2014 Easy Example","text":"<p>Validating controllers do not change anything \u2014 they only approve or reject.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#example-namespacelifecycle","title":"Example: NamespaceLifecycle","text":"<pre><code>kubectl run nginx --image=nginx -n blue\n</code></pre> <p>Result:</p> <pre><code>Error: namespace \"blue\" not found\n</code></pre> <p>Why?</p> <ul> <li>AuthN \u2705  </li> <li>AuthZ \u2705  </li> <li>Validation \u274c (namespace does not exist)</li> </ul> <p>Note</p> <p>The request is rejected \u2014 nothing is modified.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#why-mutation-runs-before-validation","title":"\u26a0\ufe0f Why Mutation Runs Before Validation","text":"<p>Consider two rules:</p> <ul> <li>Mutating controller \u2192 create namespace if missing</li> <li>Validating controller \u2192 reject if namespace missing</li> </ul> <p>Correct order:</p> <pre><code>Mutate \u2192 namespace created\nValidate \u2192 now it exists \u2192 pass\n</code></pre> <p>Wrong order would always fail.</p> <p>Tip</p> <p>Kubernetes always runs mutating first, validating second.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#external-admission-controllers-webhooks","title":"\ud83c\udf10 External Admission Controllers (Webhooks)","text":"<p>You can create your own custom admission logic using webhooks.</p> <p>Two webhook types:</p> <ul> <li>MutatingAdmissionWebhook</li> <li>ValidatingAdmissionWebhook</li> </ul> <p>Kubernetes sends the request to your webhook server \u2192 your code decides.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#webhook-flow-concept","title":"\ud83c\udfd7\ufe0f Webhook Flow (Concept)","text":"<pre><code>API Server\n   \u2502\nBuilt\u2011in Admission Controllers\n   \u2502\nWebhook Call \u2192 Your Webhook Service\n   \u2502\nAllow / Reject / Patch\n</code></pre> <p>Abstract</p> <p>Your webhook server can run inside the cluster or externally.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#mutating-webhook-yaml-example","title":"\ud83e\uddfe Mutating Webhook \u2014 YAML Example","text":"<pre><code>apiVersion: admissionregistration.k8s.io/v1\nkind: MutatingWebhookConfiguration\nmetadata:\n  name: add-label-webhook\nwebhooks:\n  - name: add-label.example.com\n    clientConfig:\n      service:\n        name: webhook-service\n        namespace: default\n        path: /mutate\n      caBundle: &lt;BASE64_CA_CERT&gt;\n    rules:\n      - operations: [\"CREATE\"]\n        apiGroups: [\"\"]\n        apiVersions: [\"v1\"]\n        resources: [\"pods\"]\n</code></pre> <p>Use cases:</p> <ul> <li>Add labels automatically</li> <li>Inject sidecars</li> <li>Add security context</li> <li>Set defaults</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#validating-webhook-yaml-example","title":"\ud83e\uddfe Validating Webhook \u2014 YAML Example","text":"<pre><code>apiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingWebhookConfiguration\nmetadata:\n  name: validate-image-webhook\nwebhooks:\n  - name: validate.example.com\n    clientConfig:\n      service:\n        name: webhook-service\n        namespace: default\n        path: /validate\n      caBundle: &lt;BASE64_CA_CERT&gt;\n    rules:\n      - operations: [\"CREATE\"]\n        apiGroups: [\"\"]\n        apiVersions: [\"v1\"]\n        resources: [\"pods\"]\n</code></pre> <p>Use cases:</p> <ul> <li>Block latest tag</li> <li>Block root user containers</li> <li>Enforce labels</li> <li>Restrict registries</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#what-your-webhook-server-receives","title":"\ud83e\udde0 What Your Webhook Server Receives","text":"<p>Webhook receives an AdmissionReview JSON with:</p> <ul> <li>user info</li> <li>operation type</li> <li>object spec</li> <li>resource type</li> </ul> <p>It must reply:</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#allow","title":"Allow","text":"<pre><code>{ \"allowed\": true }\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#reject","title":"Reject","text":"<pre><code>{\n  \"allowed\": false,\n  \"status\": { \"message\": \"Policy violation\" }\n}\n</code></pre> <p>Mutating webhooks can also return a JSON patch.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#mutation-patch-concept","title":"\ud83e\uddea Mutation Patch Concept","text":"<p>Example patch instruction:</p> <pre><code>add \u2192 /metadata/labels/user \u2192 \"john\"\n</code></pre> <p>Result:</p> <p>Pod gets label automatically before creation.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.14%20Validating-and-Mutating-Admission-Controllers/#key-takeaways","title":"\u2705 Key Takeaways","text":"<p>Summary</p> <ul> <li>Admission Controllers = final policy gate</li> <li>Two types: Mutating and Validating</li> <li>Mutating = modify requests</li> <li>Validating = allow or reject only</li> <li>Mutation runs before validation</li> <li>Webhooks enable custom logic</li> <li>Used for security, defaults, and governance</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.15%20practice-links/","title":"2.15 practice links","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.15%20practice-links/#practice-tests","title":"\ud83e\uddea Practice Tests","text":"<p>Credits</p> <p>The following practice tests are provided by KodeKloud Labs and are part of the Certified Kubernetes Administrator course by Mumshad Mannambeth on Udemy.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/2.Scheduling/2.15%20practice-links/#available-practice-tests","title":"\u2705 Available Practice Tests","text":"<ul> <li>Manual Scheduling</li> <li>Labels and Selectors</li> <li>Taints and Tolerations</li> <li>Node Affinity</li> <li>Resource Limits</li> <li>DaemonSets</li> <li>Static Pods</li> <li>Priority Class</li> <li> <p>Multiple Schedulers</p> </li> <li> <p>Admission Controllers</p> </li> <li> <p>Validating and Mutating Admission Controllers</p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.1%20Monitor%20Cluster%20Components%20%28Metrics%20Server%29/","title":"3.1 Monitor Cluster Components (Metrics Server)","text":"<p>Kubernetes does not ship with a full monitoring stack by default, but it provides a resource metrics pipeline that lets you quickly check CPU and memory usage of nodes and pods using Metrics Server.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.1%20Monitor%20Cluster%20Components%20%28Metrics%20Server%29/#what-you-monitor-in-a-kubernetes-cluster","title":"\ud83c\udfaf What You Monitor in a Kubernetes Cluster","text":"<p>At a minimum, you should be able to see:</p> <ul> <li>Number of nodes</li> <li>Node health status</li> <li>Node CPU &amp; memory usage</li> <li>Pod CPU &amp; memory usage</li> <li>Which workloads are consuming resources</li> </ul> <p>Note</p> <p>Built\u2011in metrics are current usage only. Historical graphs require tools like Prometheus or commercial monitoring platforms.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.1%20Monitor%20Cluster%20Components%20%28Metrics%20Server%29/#monitoring-tool-options","title":"\ud83e\udde9 Monitoring Tool Options","text":"<p>Common solutions:</p> <ul> <li>Metrics Server \u2192 lightweight, real\u2011time usage</li> <li>Prometheus \u2192 full metrics + history</li> <li>Elastic Stack \u2192 logs + metrics</li> <li>Datadog / Dynatrace \u2192 managed monitoring</li> </ul> <p>Tip</p> <p>For CKA/CKAD exams and quick troubleshooting, Metrics Server + kubectl top is what you must know.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.1%20Monitor%20Cluster%20Components%20%28Metrics%20Server%29/#what-is-metrics-server","title":"\ud83d\udce6 What is Metrics Server","text":"<p>Metrics Server is a cluster add\u2011on that:</p> <ul> <li>Collects CPU &amp; memory metrics</li> <li>Reads metrics from kubelets</li> <li>Aggregates node &amp; pod usage</li> <li>Stores data in memory only</li> <li>Powers <code>kubectl top</code> commands</li> </ul> <p>Warning</p> <p>Metrics Server is not for long\u2011term storage or dashboards.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.1%20Monitor%20Cluster%20Components%20%28Metrics%20Server%29/#how-metrics-are-collected","title":"\u2699\ufe0f How Metrics Are Collected","text":"<p>Metrics flow inside the cluster like this:</p> <pre><code>Pods \u2192 cAdvisor \u2192 kubelet \u2192 Metrics Server \u2192 kubectl top\n</code></pre> <p>Step by step:</p> <ol> <li>Containers generate usage data</li> <li>cAdvisor inside kubelet reads container stats</li> <li>kubelet exposes metrics API</li> <li>Metrics Server pulls metrics</li> <li><code>kubectl top</code> displays results</li> </ol> <p>Abstract</p> <p>kubelet + cAdvisor = metric source, Metrics Server = metric aggregator.</p> <p>User commands:</p> <pre><code>kubectl top node\nkubectl top pod\n</code></pre> <p>These commands query Metrics Server \u2014 not kubelet directly.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.1%20Monitor%20Cluster%20Components%20%28Metrics%20Server%29/#install-metrics-server","title":"\ud83d\ude80 Install Metrics Server","text":"MinikubeOther Clusters <pre><code>minikube addons enable metrics-server\n</code></pre> <p>Success</p> <p>Fastest method for local clusters.</p> <pre><code>git clone https://github.com/kubernetes-sigs/metrics-server.git\nkubectl apply -f metrics-server/manifests/\n</code></pre> <p>This deploys:</p> <ul> <li>Deployment</li> <li>Service</li> <li>RBAC roles</li> <li>ClusterRoleBindings</li> </ul> <p>Note</p> <p>Wait 1\u20132 minutes for metrics to appear.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.1%20Monitor%20Cluster%20Components%20%28Metrics%20Server%29/#view-node-metrics","title":"\ud83d\udcca View Node Metrics","text":"<pre><code>kubectl top node\n</code></pre> <p>Example:</p> <pre><code>NAME     CPU(cores)   MEMORY(bytes)\nnode1    166m         1373Mi\nnode2    36m          1046Mi\n</code></pre> <p>Shows:</p> <ul> <li>CPU in millicores</li> <li>Memory usage</li> <li>Current load</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.1%20Monitor%20Cluster%20Components%20%28Metrics%20Server%29/#view-pod-metrics","title":"\ud83d\udcca View Pod Metrics","text":"<pre><code>kubectl top pod\n</code></pre> <p>Example:</p> <pre><code>NAME    CPU(cores)   MEMORY(bytes)\nnginx   12m          55Mi\nredis   8m           40Mi\n</code></pre> <p>Example</p> <p>Quickly identify high\u2011usage pods.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.1%20Monitor%20Cluster%20Components%20%28Metrics%20Server%29/#exam-facts","title":"\ud83e\udde0 Exam Facts","text":"<p>Question</p> <p>Does Metrics Server store history?</p> <p>No \u2014 memory only.</p> <p>Question</p> <p>How many Metrics Servers per cluster?</p> <p>Exactly one.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.1%20Monitor%20Cluster%20Components%20%28Metrics%20Server%29/#if-metrics-are-missing","title":"\u26a0\ufe0f If Metrics Are Missing","text":"<p>If you see:</p> <pre><code>metrics not available\n</code></pre> <p>Check:</p> <ul> <li>Metrics Server pod running</li> <li>Deployment healthy</li> <li>Wait after install</li> <li>kubelet TLS settings compatible</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.1%20Monitor%20Cluster%20Components%20%28Metrics%20Server%29/#quick-summary","title":"\u2705 Quick Summary","text":"<p>Summary</p> <ul> <li>Metrics Server gives live CPU/memory metrics</li> <li>Uses kubelet + cAdvisor data</li> <li>No historical storage</li> <li>Enables kubectl top commands</li> <li>Install via addon or manifests</li> <li>Required knowledge for exams</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/","title":"3.2 Managing Application Logs","text":"<p>Kubernetes provides simple built\u2011in commands to view application logs from containers and pods.  </p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#why-application-logs-matter","title":"\ud83c\udfaf Why Application Logs Matter","text":"<p>Application logs help you:</p> <ul> <li>Debug application failures</li> <li>Track user activity</li> <li>Inspect runtime errors</li> <li>Verify container behavior</li> <li>Troubleshoot pod crashes</li> </ul> <p>Note</p> <p>Kubernetes itself does not provide long\u2011term log storage. It only exposes container logs. Use external tools (ELK, Loki, etc.) for centralized logging.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#docker-logging-basics","title":"\ud83d\udc33 Docker Logging Basics","text":"<p>Containers usually write logs to:</p> <ul> <li>stdout</li> <li>stderr</li> </ul> <p>Docker captures these streams and makes them available via the Docker CLI.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#run-container-in-background","title":"Run Container in Background","text":"<pre><code>docker run -d kodekloud/event-simulator\n</code></pre> <p>Since it runs in detached mode, logs are not shown in the terminal.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#view-docker-logs","title":"View Docker Logs","text":"<pre><code>docker logs &lt;container-id&gt;\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#stream-logs-live","title":"Stream Logs Live","text":"<pre><code>docker logs -f &lt;container-id&gt;\n</code></pre> <p>Tip</p> <p><code>-f</code> means follow \u2014 stream logs in real time.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#docker-logging-flow-diagram","title":"\ud83e\udded Docker Logging Flow (Diagram)","text":"<pre><code>Application inside container\n        \u2502\n        \u25bc\n stdout / stderr\n        \u2502\n        \u25bc\n Docker runtime\n        \u2502\n        \u25bc\n docker logs / docker logs -f\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#kubernetes-logging-basics","title":"\u2638\ufe0f Kubernetes Logging Basics","text":"<p>In Kubernetes, logs are accessed using:</p> <pre><code>kubectl logs\n</code></pre> <p>Kubernetes reads container stdout/stderr through kubelet running on each node.</p> <p>Abstract</p> <p>kubectl \u2192 API Server \u2192 kubelet \u2192 container logs</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#kubernetes-logging-flow-diagram","title":"\ud83d\udd04 Kubernetes Logging Flow (Diagram)","text":"<pre><code>Container Application\n        \u2502\n        \u25bc\n stdout / stderr\n        \u2502\n        \u25bc\n kubelet (node agent)\n        \u2502\n        \u25bc\n Kubernetes API Server\n        \u2502\n        \u25bc\n kubectl logs\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#create-pod-for-log-demo","title":"\ud83d\ude80 Create Pod for Log Demo","text":"<p>Example pod using event simulator image:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: event-simulator-pod\nspec:\n  containers:\n    - name: event-simulator\n      image: kodekloud/event-simulator\n</code></pre> <p>Create pod:</p> <pre><code>kubectl apply -f event-simulator.yaml\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#view-pod-logs-single-container","title":"\ud83d\udcc4 View Pod Logs (Single Container)","text":"<pre><code>kubectl logs event-simulator-pod\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#stream-logs-live_1","title":"Stream Logs Live","text":"<pre><code>kubectl logs -f event-simulator-pod\n</code></pre> <p>Success</p> <p>Behavior is similar to <code>docker logs -f</code>.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#multicontainer-pod-logging","title":"\ud83d\udce6 Multi\u2011Container Pod Logging","text":"<p>Pods can contain multiple containers.</p> <p>Example:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: event-simulator-pod\nspec:\n  containers:\n    - name: event-simulator\n      image: kodekloud/event-simulator\n\n    - name: image-processor\n      image: some-image-processor\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#logs-command-without-container-name","title":"\u2757 Logs Command Without Container Name","text":"<pre><code>kubectl logs event-simulator-pod\n</code></pre> <p>Result:</p> <ul> <li>Command fails</li> <li>Kubernetes asks for container name</li> </ul> <p>Warning</p> <p>For multi\u2011container pods, container name is required.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#correct-multicontainer-command","title":"\u2705 Correct Multi\u2011Container Command","text":"<pre><code>kubectl logs -f event-simulator-pod event-simulator\n</code></pre> <p>Format:</p> <pre><code>kubectl logs -f &lt;pod-name&gt; &lt;container-name&gt;\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#multicontainer-log-selection-diagram","title":"\ud83e\udded Multi\u2011Container Log Selection (Diagram)","text":"<pre><code>Pod\n \u251c\u2500\u2500 container: event-simulator\n \u2514\u2500\u2500 container: image-processor\n\nkubectl logs pod \u2192 \u274c ambiguous\nkubectl logs pod event-simulator \u2192 \u2705 works\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#useful-log-options","title":"\ud83d\udd0d Useful Log Options","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#previous-container-logs-after-crash","title":"Previous Container Logs (After Crash)","text":"<pre><code>kubectl logs --previous &lt;pod&gt;\n</code></pre> <p>Example</p> <p>Useful when a container restarted and you need logs from the previous run.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#logs-with-namespace","title":"Logs with Namespace","text":"<pre><code>kubectl logs -n dev mypod\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#exam-tips","title":"\ud83e\udde0 Exam Tips","text":"<p>Question</p> <p>Where do Kubernetes container logs come from?</p> <p>From container stdout/stderr, captured by kubelet.</p> <p>Question</p> <p>Do you need extra setup to view pod logs?</p> <p>No \u2014 built\u2011in with <code>kubectl logs</code>.</p> <p>Question</p> <p>What if a pod has multiple containers?</p> <p>You must specify the container name.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#limitations","title":"\u26a0\ufe0f Limitations","text":"<p>Warning</p> <ul> <li>No built\u2011in long\u2011term retention  </li> <li>Logs lost if container is removed  </li> <li>Use centralized logging for production</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#quick-summary","title":"\u2705 Quick Summary","text":"<p>Summary</p> <ul> <li>Applications log to stdout/stderr</li> <li>Docker \u2192 docker logs</li> <li>Kubernetes \u2192 kubectl logs</li> <li>Use -f to stream logs</li> <li>Multi\u2011container pods require container name</li> <li>kubelet provides container logs</li> <li>No built\u2011in long\u2011term storage</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#centralized-logging-tools-for-kubernetes-production-guide","title":"Centralized Logging Tools for Kubernetes (Production Guide)","text":"<p>Centralized logging in production Kubernetes environments is used to:</p> <ul> <li>Collect logs from all nodes and pods</li> <li>Aggregate logs in one place</li> <li>Store logs long-term</li> <li>Search and filter logs quickly</li> <li>Visualize logs with dashboards</li> <li>Trigger alerts on errors and patterns</li> </ul> <p>Instead of checking logs pod-by-pod, centralized logging gives you cluster-wide visibility.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#why-centralized-logging-is-needed","title":"\ud83c\udfaf Why Centralized Logging Is Needed","text":"<p>Default Kubernetes logging:</p> <ul> <li>Uses <code>kubectl logs</code></li> <li>Reads container stdout/stderr</li> <li>No long-term retention</li> <li>No cross-pod search</li> <li>No built-in dashboards</li> </ul> <p>Warning</p> <p>Production clusters should always use a centralized logging stack instead of relying only on kubectl logs.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#common-kubernetes-logging-architecture","title":"\ud83c\udfd7\ufe0f Common Kubernetes Logging Architecture","text":"<p>Typical centralized logging pipeline:</p> <pre><code>Pods / Containers\n      \u2193\nNode Log Collector (DaemonSet)\n      \u2193\nLog Aggregator / Storage\n      \u2193\nSearch + Dashboard UI\n</code></pre> <p>Collectors usually run as a DaemonSet on every node and read:</p> <ul> <li>/var/log/containers</li> <li>container runtime logs</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#most-popular-open-source-logging-stacks","title":"\u2705 Most Popular Open Source Logging Stacks","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#elk-stack","title":"\ud83d\udce6 ELK Stack","text":"<p>ELK = Elasticsearch + Logstash + Kibana</p> <p>Components:</p> <ul> <li>Elasticsearch \u2192 stores and indexes logs</li> <li>Logstash \u2192 parses and transforms logs</li> <li>Kibana \u2192 dashboards and search UI</li> </ul> <p>Typical flow:</p> <pre><code>Pods \u2192 Fluentd \u2192 Logstash \u2192 Elasticsearch \u2192 Kibana\n</code></pre> <p>Pros:</p> <ul> <li>Very powerful search</li> <li>Rich dashboards</li> <li>Mature ecosystem</li> </ul> <p>Cons:</p> <ul> <li>Heavy resource usage</li> <li>More operational overhead</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#efk-stack-kubernetes-favorite","title":"\u26a1 EFK Stack (Kubernetes Favorite)","text":"<p>EFK = Elasticsearch + Fluentd + Kibana</p> <p>Logstash is replaced by Fluentd.</p> <p>Flow:</p> <pre><code>Containers \u2192 Fluentd (DaemonSet) \u2192 Elasticsearch \u2192 Kibana\n</code></pre> <p>Pros:</p> <ul> <li>Kubernetes-friendly</li> <li>Easier than full ELK</li> <li>Widely used in clusters</li> </ul> <p>Cons:</p> <ul> <li>Still resource heavy</li> <li>Elasticsearch needs tuning</li> </ul> <p>Tip</p> <p>EFK is the most common open-source Kubernetes logging stack.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#fluent-bit-lightweight-collector","title":"\ud83e\udeb6 Fluent Bit (Lightweight Collector)","text":"<p>Fluent Bit is a lightweight log shipper often used instead of Fluentd.</p> <p>Flow:</p> <pre><code>Containers \u2192 Fluent Bit \u2192 Backend (Elastic / Loki / Cloud)\n</code></pre> <p>Pros:</p> <ul> <li>Very low CPU and memory</li> <li>Fast</li> <li>Ideal for large clusters</li> </ul> <p>Cons:</p> <ul> <li>Less processing capability than Fluentd</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#modern-lightweight-alternative","title":"\ud83d\udcca Modern Lightweight Alternative","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#grafana-loki-stack","title":"\ud83d\udfe3 Grafana Loki Stack","text":"<p>Loki + Promtail + Grafana</p> <p>Components:</p> <ul> <li>Loki \u2192 log storage</li> <li>Promtail \u2192 log collector</li> <li>Grafana \u2192 dashboards</li> </ul> <p>Flow:</p> <pre><code>Pods \u2192 Promtail \u2192 Loki \u2192 Grafana\n</code></pre> <p>Pros:</p> <ul> <li>Much cheaper than Elasticsearch</li> <li>Label-based indexing</li> <li>Simple to operate</li> <li>Fast growing adoption</li> </ul> <p>Cons:</p> <ul> <li>Different query model than ELK</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#managed-cloud-logging-platforms","title":"\u2601\ufe0f Managed Cloud Logging Platforms","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#aws-cloudwatch-logs","title":"\ud83d\udfe6 AWS CloudWatch Logs","text":"<p>Used with EKS.</p> <p>Flow:</p> <pre><code>Pods \u2192 Fluent Bit \u2192 CloudWatch Logs\n</code></pre> <p>Features:</p> <ul> <li>Fully managed</li> <li>Built-in alerts</li> <li>No storage management</li> <li>Native AWS integration</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#azure-monitor-log-analytics","title":"\ud83d\udfe5 Azure Monitor / Log Analytics","text":"<p>Used with AKS.</p> <p>Features:</p> <ul> <li>Container Insights</li> <li>Central dashboards</li> <li>Integrated metrics + logs</li> <li>Managed service</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#google-cloud-logging","title":"\ud83d\udfe8 Google Cloud Logging","text":"<p>Used with GKE.</p> <p>Features:</p> <ul> <li>Automatic log collection</li> <li>No setup required</li> <li>Integrated with GCP monitoring</li> <li>Built-in search and alerts</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#enterprise-saas-logging-tools","title":"\ud83d\udcbc Enterprise / SaaS Logging Tools","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#datadog","title":"\ud83d\udcc8 Datadog","text":"<ul> <li>Logs + metrics + traces</li> <li>Strong Kubernetes integration</li> <li>Excellent dashboards</li> <li>SaaS platform</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#splunk","title":"\ud83e\udde0 Splunk","text":"<ul> <li>Enterprise log analytics</li> <li>Advanced search and correlation</li> <li>Large-scale deployments</li> <li>Compliance-friendly</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#dynatrace","title":"\ud83d\udd0d Dynatrace","text":"<ul> <li>Full observability platform</li> <li>Logs + APM + infrastructure metrics</li> <li>AI-assisted analysis</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#kubernetes-deployment-pattern","title":"\ud83e\uddf0 Kubernetes Deployment Pattern","text":"<p>Most production setups use:</p> <ul> <li>DaemonSet log collectors:</li> <li>Fluentd</li> <li>Fluent Bit</li> <li>Promtail</li> </ul> <p>Collectors:</p> <ul> <li>Run on every node</li> <li>Read container log files</li> <li>Forward logs to backend storage</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#production-recommendations","title":"\ud83c\udfc6 Production Recommendations","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#most-common-open-source-stack","title":"\ud83e\udd47 Most Common Open Source Stack","text":"<p>EFK (Elasticsearch + Fluentd + Kibana)</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#lightweight-modern-stack","title":"\ud83e\udd48 Lightweight Modern Stack","text":"<p>Loki + Promtail + Grafana</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#easiest-for-cloud-clusters","title":"\ud83e\udd49 Easiest for Cloud Clusters","text":"<p>Cloud provider logging:</p> <ul> <li>CloudWatch (AWS)</li> <li>Azure Monitor</li> <li>Google Cloud Logging</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.2-Managing-Application-Logs/#quick-summary_1","title":"\u2705 Quick Summary","text":"<p>Summary</p> <ul> <li>kubectl logs is not enough for production</li> <li>Use centralized logging stacks</li> <li>Most common: EFK</li> <li>Lightweight option: Loki</li> <li>Best for cloud: managed logging services</li> <li>Use DaemonSets for node-level log collection</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/3.Logging-and-Monitoring/3.3%20Practice-links/","title":"3.3 Practice links","text":"<p>Credits</p> <p>The following practice tests are provided by KodeKloud Labs and are part of the Certified Kubernetes Administrator course by Mumshad Mannambeth on Udemy.</p> <ul> <li> <p>Monitoring Cluster Components</p> </li> <li> <p>Monitor Application Logs</p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/","title":"4.01 Rolling Updates and Rollbacks","text":"<p>Kubernetes Deployments provide built\u2011in support for safe upgrades and fast recovery using:</p> <ul> <li>\u2705 Rolling Updates \u2014 upgrade without downtime  </li> <li>\u23ea Rollbacks \u2014 revert to a previous working version  </li> </ul> <p>Each change to a Deployment creates a new revision, so Kubernetes can track versions and switch back if needed.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#what-is-a-rollout","title":"\ud83c\udfaf What Is a Rollout","text":"<p>A rollout is triggered whenever a Deployment is created or its Pod template changes.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#a-rollout-happens-when-you","title":"A rollout happens when you:","text":"<ul> <li>Create a Deployment</li> <li>Change container image</li> <li>Modify labels / env / command</li> <li>Change pod template fields</li> </ul> <p>Each rollout creates:</p> <ul> <li>A new ReplicaSet</li> <li>A new revision number</li> </ul> <p>Note</p> <p>Think of a rollout as a new version release of your Deployment inside the cluster.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#deployment-revision-model","title":"\ud83e\uddf1 Deployment Revision Model","text":"<p>Every Deployment keeps a history of ReplicaSets (versions).</p> <pre><code>Deployment\n   \u2502\n   \u251c\u2500 Revision 1 \u2192 ReplicaSet A \u2192 Pods (v1)\n   \u251c\u2500 Revision 2 \u2192 ReplicaSet B \u2192 Pods (v2)\n   \u2514\u2500 Revision 3 \u2192 ReplicaSet C \u2192 Pods (v3)\n</code></pre> <ul> <li>Only one ReplicaSet serves full traffic after rollout completes</li> <li>Older ReplicaSets are kept for rollback</li> </ul> <p>Tip</p> <p>ReplicaSets are the \u201cversion history\u201d behind a Deployment.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#deployment-strategies","title":"\ud83d\ude80 Deployment Strategies","text":"<p>Kubernetes supports two upgrade strategies.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#recreate-strategy","title":"\ud83d\udd34 Recreate Strategy","text":"<p>All old pods are deleted first, then new pods are created.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#flow","title":"Flow","text":"<pre><code>Old Pods \u2192 deleted \u2192 \u274c downtime \u2192 New Pods created\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#behavior","title":"Behavior","text":"<ul> <li>Simple</li> <li>Causes application downtime</li> <li>Not default</li> </ul> <p>Warning</p> <p>Users will experience outage during upgrade with Recreate strategy.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#rolling-update-strategy-default","title":"\ud83d\udfe2 Rolling Update Strategy (Default)","text":"<p>Pods are replaced gradually.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#flow_1","title":"Flow","text":"<pre><code>Old: \u2588\u2588\u2588\u2588\u2588\nStep1: \u2588\u2588\u2588\u2588\u2591 + \u2591\nStep2: \u2588\u2588\u2588\u2591\u2591 + \u2588\u2588\nStep3: \u2588\u2588\u2591\u2591\u2591 + \u2588\u2588\u2588\nNew:  \u2591\u2591\u2591\u2591\u2591 + \u2588\u2588\u2588\u2588\u2588\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#behavior_1","title":"Behavior","text":"<ul> <li>Old and new pods run together temporarily</li> <li>No downtime (if readiness probes are correct)</li> <li>Default strategy</li> </ul> <p>Success</p> <p>RollingUpdate is used automatically if no strategy is specified.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#strategy-configuration-yaml","title":"\u2699\ufe0f Strategy Configuration (YAML)","text":"Rolling Update (default)Recreate <pre><code>strategy:\n  type: RollingUpdate\n</code></pre> <pre><code>strategy:\n  type: Recreate\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#how-to-update-a-deployment","title":"\ud83d\udd04 How to Update a Deployment","text":"<p>You can trigger a new rollout in two main ways.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#method-1-update-yaml-and-apply","title":"Method 1 \u2014 Update YAML and Apply","text":"<p>Edit Deployment YAML, then:</p> <pre><code>kubectl apply -f deployment.yaml\n</code></pre> <p>Kubernetes will:</p> <ul> <li>Create new ReplicaSet</li> <li>Start rollout</li> <li>Create new revision</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#method-2-update-image-directly","title":"Method 2 \u2014 Update Image Directly","text":"<pre><code>kubectl set image deployment/myapp nginx=nginx:1.9.1\n</code></pre> <p>Tip</p> <p>Fast for quick updates, but your YAML file will not reflect this change automatically.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#rollout-status-and-history","title":"\ud83d\udcca Rollout Status and History","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#check-rollout-progress","title":"Check rollout progress","text":"<pre><code>kubectl rollout status deployment/myapp\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#view-revision-history","title":"View revision history","text":"<pre><code>kubectl rollout history deployment/myapp\n</code></pre> <p>Example:</p> <pre><code>REVISION   CHANGE-CAUSE\n1          initial deploy\n2          image update\n</code></pre> <p>Example</p> <p>Useful to identify which revision to roll back to.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#what-happens-during-rolling-update","title":"\ud83e\udde9 What Happens During Rolling Update","text":"<p>Behind the scenes Kubernetes creates a new ReplicaSet and shifts traffic gradually.</p> <pre><code>Start:\nReplicaSet A \u2192 5 pods (v1)\n\nDuring:\nReplicaSet A \u2192 3 pods\nReplicaSet B \u2192 2 pods\n\nLater:\nReplicaSet A \u2192 1 pod\nReplicaSet B \u2192 4 pods\n\nEnd:\nReplicaSet A \u2192 0 pods\nReplicaSet B \u2192 5 pods (v2)\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#view-replicasets","title":"\ud83d\udd0d View ReplicaSets","text":"<pre><code>kubectl get replicasets\n</code></pre> <p>You will observe:</p> <ul> <li>Old ReplicaSet scaled down</li> <li>New ReplicaSet scaled up</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#rollback-a-deployment","title":"\u23ea Rollback a Deployment","text":"<p>If a new version is broken, revert instantly.</p> <pre><code>kubectl rollout undo deployment/myapp\n</code></pre> <p>Kubernetes will:</p> <ul> <li>Scale down new ReplicaSet</li> <li>Scale up previous ReplicaSet</li> <li>Restore last working version</li> </ul> <p>Success</p> <p>Rollback is fast because old ReplicaSet already exists.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#rollback-flow","title":"\u23ea Rollback Flow","text":"<pre><code>Current \u2192 ReplicaSet B \u2192 bad version \u2192 5 pods\n\nRollback \u2192\n\nReplicaSet B \u2192 scaled to 0\nReplicaSet A \u2192 scaled to 5\n\nPrevious version restored\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#command-cheat-sheet","title":"\ud83d\udee0\ufe0f Command Cheat Sheet","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#create","title":"Create","text":"<pre><code>kubectl create -f deployment.yaml\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#list","title":"List","text":"<pre><code>kubectl get deployments\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#update","title":"Update","text":"<pre><code>kubectl apply -f deployment.yaml\nkubectl set image deployment/myapp nginx=nginx:1.9.1\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#status","title":"Status","text":"<pre><code>kubectl rollout status deployment/myapp\nkubectl rollout history deployment/myapp\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#rollback","title":"Rollback","text":"<pre><code>kubectl rollout undo deployment/myapp\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#exam-tips","title":"\ud83e\udde0 Exam Tips","text":"<p>Question</p> <p>Default deployment strategy?</p> <p>RollingUpdate</p> <p>Question</p> <p>What creates a new revision?</p> <p>Any Pod template change</p> <p>Question</p> <p>Does rollback create new pods?</p> <p>Yes \u2014 previous ReplicaSet pods are scaled up again.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.01%20Rolling-Updates-and-Rollbacks-MkDocs/#quick-summary","title":"\u2705 Quick Summary","text":"<p>Summary</p> <ul> <li>Rollout = new Deployment revision</li> <li>Each rollout creates a new ReplicaSet</li> <li>RollingUpdate is default</li> <li>Recreate causes downtime</li> <li>rollout status shows progress</li> <li>rollout history shows revisions</li> <li>rollout undo restores previous version</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/","title":"4.02  Commands and Arguments in Docker &amp; Kubernetes","text":"<p>This guide explains how commands and arguments work in both Docker and Kubernetes in a simple way.</p> <p>It focuses on:</p> <ul> <li>How containers decide what to run at startup</li> <li>How CMD and ENTRYPOINT behave in Docker</li> <li>How Kubernetes <code>command</code> and <code>args</code> override image behavior</li> <li>Correct patterns and common mistakes</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#commands-and-arguments-in-docker","title":"\ud83d\udc33 Commands and Arguments in Docker","text":"<p>Docker containers run one main process. When that process exits, the container stops.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#core-concept-container-main-process","title":"\ud83c\udfaf Core Concept \u2014 Container = Main Process","text":"<p>A container is not a virtual machine. It does not boot an OS. It runs a single primary process.</p> <p>Lifecycle:</p> <pre><code>Container start \u2192 Main process runs \u2192 Process exits \u2192 Container stops\n</code></pre> <p>Startup command can come from:</p> <ul> <li>Dockerfile <code>CMD</code></li> <li>Dockerfile <code>ENTRYPOINT</code></li> <li>Command passed in <code>docker run</code></li> </ul> <p>Note</p> <p>If there is no long\u2011running process = container exits immediately.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#why-docker-run-ubuntu-stops-immediately","title":"\u25b6\ufe0f Why <code>docker run ubuntu</code> Stops Immediately","text":"Run <pre><code>docker run ubuntu\n</code></pre> <p>What happens:</p> <ul> <li>Ubuntu image default command = bash</li> <li>No interactive terminal attached</li> <li>bash exits</li> <li>container stops</li> </ul> Verify <pre><code>docker ps\ndocker ps -a\n</code></pre> <p>Warning</p> <p>If the startup command finishes, container status becomes Exited.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#override-default-command-at-runtime","title":"\u23f1\ufe0f Override Default Command at Runtime","text":"<p>Anything after the image name overrides Dockerfile CMD.</p> <pre><code>docker run ubuntu sleep 5\n</code></pre> <p>Final startup command:</p> <pre><code>sleep 5\n</code></pre> <p>Tip</p> <p>Runtime command replaces CMD completely.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#cmd-default-command","title":"\ud83e\uddf1 CMD \u2014 Default Command","text":"<p>CMD defines the default command + arguments if none are provided at runtime.</p> Shell FormExec (JSON) Form \u2014 Recommended <pre><code>CMD sleep 5\n</code></pre> <pre><code>CMD [\"sleep\", \"5\"]\n</code></pre> <p>Success</p> <p>Always prefer JSON form \u2014 safer argument parsing.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#wrong-cmd-json-format","title":"\u274c Wrong CMD JSON Format","text":"<pre><code>CMD [\"sleep 5\"]\n</code></pre> <p>Bug</p> <p>Executable and arguments must be separate array elements.</p> <p>Correct:</p> <pre><code>CMD [\"sleep\",\"5\"]\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#cmd-is-replaced-by-runtime-command","title":"\ud83d\udd01 CMD Is Replaced by Runtime Command","text":"<p>Dockerfile:</p> <pre><code>CMD [\"sleep\",\"5\"]\n</code></pre> <p>Runtime:</p> <pre><code>docker run myimg sleep 10\n</code></pre> <p>Final command:</p> <pre><code>sleep 10\n</code></pre> <p>Note</p> <p>Runtime command fully replaces CMD.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#entrypoint-fixed-executable","title":"\ud83d\udeaa ENTRYPOINT \u2014 Fixed Executable","text":"<p>ENTRYPOINT defines the base executable.</p> <p>Runtime values are appended as arguments.</p> <pre><code>ENTRYPOINT [\"sleep\"]\n</code></pre> <pre><code>docker run myimg 10\n</code></pre> <p>Final command:</p> <pre><code>sleep 10\n</code></pre> <p>Abstract</p> <p>ENTRYPOINT = fixed program CMD = default parameters</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#entrypoint-without-default-args","title":"\u26a0\ufe0f ENTRYPOINT Without Default Args","text":"<pre><code>ENTRYPOINT [\"sleep\"]\n</code></pre> <pre><code>docker run myimg\n</code></pre> <p>Result:</p> <pre><code>sleep: missing operand\n</code></pre> <p>Warning</p> <p>ENTRYPOINT needs arguments \u2014 provide via CMD or runtime.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#best-practice-entrypoint-cmd","title":"\u2705 Best Practice \u2014 ENTRYPOINT + CMD","text":"<pre><code>FROM ubuntu\nENTRYPOINT [\"sleep\"]\nCMD [\"5\"]\n</code></pre> No runtime argWith runtime arg <pre><code>docker run myimg\n</code></pre> <p>Runs \u2192 <code>sleep 5</code></p> <pre><code>docker run myimg 20\n</code></pre> <p>Runs \u2192 <code>sleep 20</code></p> <p>Success</p> <p>ENTRYPOINT + CMD = best pattern for flexible containers.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#override-entrypoint-at-runtime","title":"\ud83d\udd27 Override ENTRYPOINT at Runtime","text":"<pre><code>docker run --entrypoint sleep2.0 myimg 30\n</code></pre> <p>Tip</p> <p>Useful for debugging or temporary overrides.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#docker-startup-resolution-order","title":"\ud83e\udded Docker Startup Resolution Order","text":"<pre><code>docker run command\n      \u2193\nReplaces CMD\n      \u2193\nAppended to ENTRYPOINT (if present)\n      \u2193\nFinal executed process\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#cmd-vs-entrypoint-quick-compare","title":"\ud83d\udcca CMD vs ENTRYPOINT \u2014 Quick Compare","text":"Behavior CMD ENTRYPOINT Default executable \u2705 \u2705 Default args \u2705 \u274c Runtime command Replaces Appends Best for Defaults Fixed program"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#commands-and-arguments-in-kubernetes","title":"\u2638\ufe0f Commands and Arguments in Kubernetes","text":"<p>Kubernetes lets you override container startup behavior using:</p> <ul> <li><code>command</code></li> <li><code>args</code></li> </ul> <p>These map directly to Docker behavior.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#core-idea-pod-startup-control","title":"\ud83c\udfaf Core Idea \u2014 Pod Startup Control","text":"<p>Container startup inside a Pod can come from:</p> <ul> <li>Docker ENTRYPOINT</li> <li>Docker CMD</li> <li>Pod <code>command</code></li> <li>Pod <code>args</code></li> </ul> <p>Note</p> <p>Kubernetes can override both ENTRYPOINT and CMD.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#mapping-docker-vs-kubernetes","title":"\ud83e\uddf1 Mapping \u2014 Docker vs Kubernetes","text":"Docker Kubernetes ENTRYPOINT \u27a1\ufe0f command CMD\u27a1\ufe0f args <p>Tip</p> <p>command = executable args = parameters</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#default-behavior-no-pod-overrides","title":"\u25b6\ufe0f Default Behavior (No Pod Overrides)","text":"<p>Dockerfile:</p> <pre><code>ENTRYPOINT [\"sleep\"]\nCMD [\"5\"]\n</code></pre> <p>Pod:</p> <pre><code>containers:\n  - name: sleeper\n    image: ubuntu-sleeper\n</code></pre> <p>Final command:</p> <pre><code>sleep 5\n</code></pre> <p>Success</p> <p>Image defaults are used.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#override-only-arguments-args","title":"\ud83d\udd22 Override Only Arguments (args)","text":"<p>Equivalent to:</p> <pre><code>docker run ubuntu-sleeper 10\n</code></pre> <p>Pod:</p> <pre><code>containers:\n  - name: sleeper\n    image: ubuntu-sleeper\n    args: [\"10\"]\n</code></pre> <p>Final command:</p> <pre><code>sleep 10\n</code></pre> <p>Note</p> <p>args overrides Docker CMD only.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#override-executable-command","title":"\ud83d\udd01 Override Executable (command)","text":"<p>Equivalent to Docker:</p> <pre><code>docker run --entrypoint sleep2.0 ubuntu-sleeper 10\n</code></pre> <p>Pod:</p> <pre><code>containers:\n  - name: sleeper\n    image: ubuntu-sleeper\n    command: [\"sleep2.0\"]\n    args: [\"10\"]\n</code></pre> <p>Final command:</p> <pre><code>sleep2.0 10\n</code></pre> <p>Warning</p> <p>command replaces Docker ENTRYPOINT.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#kubernetes-override-flow","title":"\ud83e\udded Kubernetes Override Flow","text":"<pre><code>Dockerfile ENTRYPOINT + CMD\n        \u2193\nImage default command\n        \u2193\nPod args \u2192 replaces CMD\nPod command \u2192 replaces ENTRYPOINT\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#common-mistake","title":"\u26a0\ufe0f Common Mistake","text":"<p>Wrong:</p> <pre><code>command: [\"sleep 10\"]\n</code></pre> <p>Bug</p> <p>Must be split into executable + argument.</p> <p>Correct:</p> <pre><code>command: [\"sleep\"]\nargs: [\"10\"]\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#minimal-test-pod","title":"\ud83e\uddea Minimal Test Pod","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: demo\nspec:\n  containers:\n    - name: sleeper\n      image: ubuntu\n      command: [\"sleep\"]\n      args: [\"15\"]\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#exam-checks","title":"\ud83e\udde0 Exam Checks","text":"<p>Question</p> <p>Which Pod field overrides Docker ENTRYPOINT?</p> <p>command</p> <p>Question</p> <p>Which Pod field overrides Docker CMD?</p> <p>args</p> <p>Question</p> <p>Are command and args arrays?</p> <p>Yes \u2014 always list form.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.02%20Commands-and-Arguments-Docker-and-K8s/#final-summary","title":"\u2705 Final Summary","text":"<p>Summary</p> <ul> <li>Containers run one main process</li> <li>Docker CMD = default args</li> <li>Docker ENTRYPOINT = fixed executable</li> <li>Runtime command replaces CMD</li> <li>Runtime args append to ENTRYPOINT</li> <li>Kubernetes command \u2194 ENTRYPOINT</li> <li>Kubernetes args \u2194 CMD</li> <li>Always use JSON/list form</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/","title":"4.03 Configure Env Variables,ConfigMaps &amp; Secrets in Applications","text":"<p>Kubernetes lets you pass configuration into containers using:</p> <ul> <li>Environment variables</li> <li>ConfigMaps</li> <li>Secrets</li> </ul> <p>This keeps configuration separate from container images and makes apps easier to manage and update.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#why-use-environment-configuration","title":"\ud83c\udfaf Why Use Environment Configuration","text":"<p>Applications often need runtime configuration such as:</p> <ul> <li>App mode (dev / prod)</li> <li>Feature flags</li> <li>Colors / themes</li> <li>DB hostnames</li> <li>Ports</li> <li>External service URLs</li> </ul> <p>Hard-coding these inside images is bad practice.</p> <p>Success</p> <p>Kubernetes supports external configuration using env, ConfigMaps, and Secrets.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#basic-environment-variable-in-a-pod","title":"\ud83e\uddea Basic Environment Variable in a Pod","text":"<p>Equivalent Docker command:</p> <pre><code>docker run -e APP_COLOR=pink simple-webapp-color\n</code></pre> <p>Kubernetes Pod YAML:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: simple-webapp-color\nspec:\n  containers:\n    - name: app\n      image: simple-webapp-color\n      ports:\n        - containerPort: 8080\n      env:\n        - name: APP_COLOR\n          value: pink\n</code></pre> <p>Note</p> <p><code>env</code> is a list \u2014 each variable is a separate item.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#environment-value-sources-3-ways","title":"\ud83e\udde9 Environment Value Sources (3 Ways)","text":"<p>Kubernetes supports three env value types:</p> <ol> <li>Plain key/value  </li> <li>ConfigMap  </li> <li>Secret  </li> </ol> Plain Key ValueFrom ConfigMapFrom Secret <pre><code>env:\n  - name: APP_COLOR\n    value: pink\n</code></pre> <pre><code>env:\n  - name: APP_COLOR\n    valueFrom:\n      configMapKeyRef:\n        name: app-config\n        key: APP_COLOR\n</code></pre> <pre><code>env:\n  - name: DB_PASSWORD\n    valueFrom:\n      secretKeyRef:\n        name: db-secret\n        key: password\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#what-is-a-configmap","title":"\ud83d\uddc2\ufe0f What Is a ConfigMap","text":"<p>A ConfigMap stores configuration as key\u2013value pairs in Kubernetes.</p> <p>Benefits:</p> <ul> <li>Central config storage</li> <li>Reusable across Pods</li> <li>No image rebuild required</li> <li>Easy updates</li> </ul> <p>Abstract</p> <p>ConfigMap = configuration outside the container image.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#create-configmap-imperative-method","title":"\u270d\ufe0f Create ConfigMap \u2014 Imperative Method","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#from-literal-values","title":"From Literal Values","text":"<pre><code>kubectl create configmap app-config \\\n  --from-literal=APP_COLOR=blue \\\n  --from-literal=APP_MODE=prod\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#from-file","title":"From File","text":"<pre><code>kubectl create configmap app-config \\\n  --from-file=app.properties\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#create-configmap-declarative-method","title":"\ud83d\udcc4 Create ConfigMap \u2014 Declarative Method","text":"<p>ConfigMap YAML:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  APP_COLOR: blue\n  APP_MODE: prod\n</code></pre> <p>Create:</p> <pre><code>kubectl apply -f configmap.yaml\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#view-configmaps","title":"\ud83d\udd0d View ConfigMaps","text":"<pre><code>kubectl get configmaps\nkubectl describe configmap app-config\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#inject-configmap-into-pod-all-keys","title":"\ud83d\ude80 Inject ConfigMap into Pod \u2014 All Keys","text":"<p>Load all keys as environment variables:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: webapp\nspec:\n  containers:\n    - name: app\n      image: simple-webapp-color\n      envFrom:\n        - configMapRef:\n            name: app-config\n</code></pre> <p>Result inside container:</p> <pre><code>APP_COLOR=blue\nAPP_MODE=prod\n</code></pre> <p>Tip</p> <p><code>envFrom</code> loads all keys from the ConfigMap.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#inject-single-configmap-key","title":"\ud83c\udfaf Inject Single ConfigMap Key","text":"<pre><code>env:\n  - name: APP_COLOR\n    valueFrom:\n      configMapKeyRef:\n        name: app-config\n        key: APP_COLOR\n</code></pre> <p>Note</p> <p>Use this when you only need specific keys.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#inject-configmap-as-volume","title":"\ud83d\udcbe Inject ConfigMap as Volume","text":"<p>ConfigMap can also be mounted as files.</p> <pre><code>volumes:\n  - name: config-vol\n    configMap:\n      name: app-config\n\ncontainers:\n  - name: app\n    image: simple-webapp-color\n    volumeMounts:\n      - name: config-vol\n        mountPath: /etc/config\n</code></pre> <p>Result inside container:</p> <pre><code>/etc/config/APP_COLOR\n/etc/config/APP_MODE\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#when-to-use-secrets-instead","title":"\u26a0\ufe0f When to Use Secrets Instead","text":"<p>Use Secrets instead of ConfigMaps for:</p> <ul> <li>Passwords</li> <li>Tokens</li> <li>Keys</li> <li>Certificates</li> </ul> <p>Warning</p> <p>ConfigMaps are NOT encrypted \u2014 Secrets are.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#exam-style-checks","title":"\u2753 Exam-Style Checks","text":"<p>Question</p> <p>Where is ConfigMap data stored?</p> <p>In Kubernetes API (etcd).</p> <p>Question</p> <p>Does ConfigMap require Pod restart after change?</p> <p>Usually yes (unless app reloads dynamically).</p> <p>Question</p> <p>Can ConfigMap be used as files?</p> <p>Yes \u2014 via volume mount.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#quick-summary","title":"\u2705 Quick Summary","text":"<p>Summary</p> <ul> <li>Use env for simple variables</li> <li>Use ConfigMaps for shared configuration</li> <li>Create via kubectl or YAML</li> <li>Inject using env, envFrom, or volumes</li> <li>envFrom loads all keys</li> <li>configMapKeyRef loads one key</li> <li>Use Secrets for sensitive data</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#kubernetes-secrets","title":"Kubernetes Secrets","text":"<p>Kubernetes Secrets are used to store and manage sensitive data such as:</p> <ul> <li>Passwords</li> <li>API keys</li> <li>Tokens</li> <li>Database credentials</li> </ul> <p>Secrets are similar to ConfigMaps \u2014 but meant for confidential values.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#why-secrets-are-needed","title":"\ud83c\udfaf Why Secrets Are Needed","text":"<p>Hard-coding credentials inside application code or Pod YAML is unsafe.</p> <p>Example (\u274c bad practice):</p> <pre><code>mysql.connect(\n  host=\"mysql\",\n  user=\"root\",\n  password=\"passwd\"\n)\n</code></pre> <p>Instead \u2014 move sensitive values into Kubernetes Secrets and inject them securely.</p> <p>Warning</p> <p>Do NOT store passwords in Pod specs or container images.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#secrets-vs-configmaps","title":"\ud83e\udde0 Secrets vs ConfigMaps","text":"Feature ConfigMap Secret Purpose Non-sensitive config Sensitive data Storage Plain text Base64 encoded Use case App settings Credentials, keys <p>Note</p> <p>Secrets are base64-encoded \u2014 not encrypted by default.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#secret-workflow-2-steps","title":"\ud83d\udd10 Secret Workflow (2 Steps)","text":"<pre><code>Step 1 \u2192 Create Secret\nStep 2 \u2192 Inject into Pod\n</code></pre> <p>Secrets can be injected as:</p> <ul> <li>Environment variables</li> <li>Single env values</li> <li>Mounted volume files</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#create-secrets-imperative-method","title":"\u2699\ufe0f Create Secrets \u2014 Imperative Method","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#from-literal-values_1","title":"From Literal Values","text":"<pre><code>kubectl create secret generic app-secret \\\n  --from-literal=DB_Host=mysql \\\n  --from-literal=DB_User=root \\\n  --from-literal=DB_Password=passwd\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#from-file_1","title":"From File","text":"<pre><code>kubectl create secret generic app-secret \\\n  --from-file=secret.properties\n</code></pre> <p>Tip</p> <p>Good when many secret keys exist.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#create-secrets-declarative-method","title":"\ud83d\udce6 Create Secrets \u2014 Declarative Method","text":"<p>Secrets YAML requires base64 encoded values.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#encode-values","title":"Encode Values","text":"<pre><code>echo -n 'mysql' | base64\necho -n 'root' | base64\necho -n 'passwd' | base64\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#secret-yaml","title":"Secret YAML","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: app-secret\ntype: Opaque\ndata:\n  DB_Host: bXlzcWw=\n  DB_User: cm9vdA==\n  DB_Password: cGFzc3dk\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f secret.yaml\n</code></pre> <p>Success</p> <p>Declarative method is preferred for GitOps.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#view-secrets","title":"\ud83d\udd0d View Secrets","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#list","title":"List","text":"<pre><code>kubectl get secrets\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#describe-values-hidden","title":"Describe (values hidden)","text":"<pre><code>kubectl describe secret app-secret\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#view-yaml-encoded-values-visible","title":"View YAML (encoded values visible)","text":"<pre><code>kubectl get secret app-secret -o yaml\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#decode-secret-value","title":"\ud83d\udd13 Decode Secret Value","text":"<pre><code>echo 'bXlzcWw=' | base64 --decode\n</code></pre> <p>Note</p> <p>Base64 encoding is reversible \u2014 enable etcd encryption for real security.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#inject-secrets-into-pods-all-as-env","title":"\ud83d\ude80 Inject Secrets into Pods \u2014 All as ENV","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: web-pod\nspec:\n  containers:\n    - name: app\n      image: myapp\n      envFrom:\n        - secretRef:\n            name: app-secret\n</code></pre> <p>Result inside container:</p> <pre><code>DB_Host\nDB_User\nDB_Password\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#inject-single-secret-key","title":"\ud83c\udfaf Inject Single Secret Key","text":"<pre><code>env:\n  - name: DB_PASSWORD\n    valueFrom:\n      secretKeyRef:\n        name: app-secret\n        key: DB_Password\n</code></pre> <p>Tip</p> <p>Use this when you only need one value.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#mount-secret-as-volume","title":"\ud83d\udcc1 Mount Secret as Volume","text":"<p>Each secret key becomes a file.</p> <pre><code>spec:\n  containers:\n    - name: app\n      image: myapp\n      volumeMounts:\n        - name: secret-vol\n          mountPath: /opt/secrets\n\n  volumes:\n    - name: secret-vol\n      secret:\n        secretName: app-secret\n</code></pre> <p>Inside container:</p> <pre><code>ls /opt/secrets\ncat /opt/secrets/DB_Password\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#secret-injection-diagram","title":"\ud83e\udded Secret Injection Diagram","text":"<pre><code>Secret Object\n   \u2502\n   \u251c\u2500\u2500 envFrom \u2192 all keys \u2192 env vars\n   \u2502\n   \u251c\u2500\u2500 secretKeyRef \u2192 single key \u2192 env var\n   \u2502\n   \u2514\u2500\u2500 volume mount \u2192 keys \u2192 files\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#important-security-notes","title":"\u26a0\ufe0f Important Security Notes","text":"<p>Warning</p> <p>Base64 is encoding \u2014 not encryption.</p> <p>Warning</p> <p>Enable etcd encryption for production clusters.</p> <p>Tip</p> <p>Use RBAC to restrict secret access.</p> <p>Tip</p> <p>Avoid committing Secret YAML with real values to Git.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#exam-style-checks_1","title":"\ud83e\uddea Exam-Style Checks","text":"<p>Question</p> <p>Are Secrets encrypted by default?</p> <p>No \u2014 only base64 encoded.</p> <p>Question</p> <p>How many steps to use Secrets?</p> <p>Create \u2192 Inject.</p> <p>Question</p> <p>Can Secrets be used as files?</p> <p>Yes \u2014 via volume mount.</p> <p>Question</p> <p>Which field injects all keys as env vars?</p> <p>envFrom + secretRef</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.03%20Env-Variables/#quick-summary_1","title":"\u2705 Quick Summary","text":"<p>Summary</p> <ul> <li>Secrets store sensitive data</li> <li>Similar to ConfigMaps but for credentials</li> <li>Values stored base64 encoded</li> <li>Create via imperative or YAML</li> <li>Inject using envFrom, secretKeyRef, or volumes</li> <li>Describe hides values</li> <li>YAML shows encoded values</li> <li>Use RBAC + etcd encryption in production</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/","title":"4.04 Encrypting Secret Data at Rest","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#official-kubernetes-secret-protection-and-encryption-documentation","title":"Official Kubernetes Secret protection and encryption documentation","text":"<p>Important Reality</p> <ul> <li>Kubernetes Secrets are not encrypted by default \u2014 they are only base64-encoded.  </li> </ul> <p>Danger</p> <p>Base64 encoding is NOT encryption. Without encryption at rest, secrets are readable from etcd.</p> <ul> <li> <p>Protection comes from how you use Secrets and cluster hardening practices.</p> </li> <li> <p>Encryption at rest ensures Secret objects are encrypted before being written to etcd.</p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#why-encryption-at-rest-matters","title":"\ud83c\udfaf Why Encryption at Rest Matters","text":"<p>Without encryption at rest:</p> <ul> <li>Secrets stored in etcd are readable</li> <li>etcd backups expose credentials</li> <li>Control plane access = secret exposure</li> <li>Compliance requirements may fail</li> </ul> <p>Success</p> <p>Production clusters should always enable encryption at rest for Secrets.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#check-if-encryption-at-rest-is-already-enabled","title":"\ud83d\udd0d Check If Encryption at Rest Is Already Enabled","text":"<p>Kubernetes API server must be started with:</p> <pre><code>--encryption-provider-config\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#check-running-process","title":"Check Running Process","text":"<pre><code>ps -aux | grep kube-api | grep encryption-provider-config\n</code></pre> If PresentIf Missing <p>Encryption config is enabled.</p> <p>Encryption at rest is NOT enabled.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#check-kube-apiserver-manifest-kubeadm-clusters","title":"Check kube-apiserver Manifest (kubeadm clusters)","text":"<pre><code>ls /etc/kubernetes/manifests/\ncat /etc/kubernetes/manifests/kube-apiserver.yaml\n</code></pre> <p>Look for:</p> <pre><code>--encryption-provider-config=\n</code></pre> <p>Warning</p> <p>If not present \u2192 Secrets are stored unencrypted in etcd.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#how-encryption-provider-works","title":"\ud83e\udde0 How Encryption Provider Works","text":"<p>Encryption is configured using:</p> <p>EncryptionConfiguration</p> <p>You choose:</p> <ul> <li>Which resources to encrypt</li> <li>Which encryption provider to use</li> <li>Which keys are used</li> </ul> <p>Example targets:</p> <pre><code>resources:\n  - secrets\n</code></pre> <p>Note</p> <p>Usually encrypt Secrets only.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#available-encryption-providers","title":"\ud83d\udd10 Available Encryption Providers","text":"<p>Provider order matters \u2014 first provider = used for encryption.</p> Provider Security Speed Notes identity none fastest No encryption aescbc good fast Common choice aesgcm strong fastest Needs rotation secretbox strong fast Modern crypto kms v2 strongest fast External KMS (best) <p>Warning</p> <p>If identity is first \u2192 NOTHING is encrypted.</p> <p>Tip</p> <p>Production: prefer KMS v2 or aescbc minimum.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#encryption-config-file-example","title":"\ud83e\uddfe Encryption Config File Example","text":"<pre><code>apiVersion: apiserver.config.k8s.io/v1\nkind: EncryptionConfiguration\nresources:\n  - resources:\n      - secrets\n    providers:\n      - aescbc:\n          keys:\n            - name: key1\n              secret: BASE64_KEY\n      - identity: {}\n</code></pre> <p>Note</p> <p>First provider encrypts. Others are used for decrypt fallback.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#generate-encryption-key","title":"\ud83d\udd11 Generate Encryption Key","text":"<pre><code>head -c 32 /dev/urandom | base64\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#place-config-on-control-plane","title":"\ud83d\udcc1 Place Config on Control Plane","text":"<pre><code>mkdir -p /etc/kubernetes/enc\n</code></pre> <p>Save as:</p> <pre><code>/etc/kubernetes/enc/enc.yaml\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#enable-encryption-in-kube-apiserver","title":"\u2699\ufe0f Enable Encryption in kube-apiserver","text":"<p>Edit:</p> <pre><code>/etc/kubernetes/manifests/kube-apiserver.yaml\n</code></pre> <p>Add:</p> <pre><code>--encryption-provider-config=/etc/kubernetes/enc/enc.yaml\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#volume-mount","title":"Volume Mount","text":"<pre><code>volumeMounts:\n- name: enc\n  mountPath: /etc/kubernetes/enc\n  readOnly: true\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#volume","title":"Volume","text":"<pre><code>volumes:\n- name: enc\n  hostPath:\n    path: /etc/kubernetes/enc\n    type: DirectoryOrCreate\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#restart-api-server","title":"\ud83d\udd04 Restart API Server","text":"<p>Static pod restarts automatically after manifest edit.</p> <p>Verify:</p> <pre><code>ps -aux | grep kube-apiserver\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#verify-encryption-works","title":"\ud83e\uddea Verify Encryption Works","text":"<p>Create secret:</p> <pre><code>kubectl create secret generic my-secret --from-literal=key=topsecret\n</code></pre> <p>Check etcd:</p> <pre><code>ETCDCTL_API=3 etcdctl get /registry/secrets/default/my-secret | hexdump -C\n</code></pre> <p>Encrypted \u2192 value not readable.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#encrypt-existing-secrets","title":"\ud83d\udd01 Encrypt Existing Secrets","text":"<p>Encryption applies only to new writes.</p> <p>Re-encrypt:</p> <pre><code>kubectl get secrets --all-namespaces -o json | kubectl replace -f -\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#best-practices-that-make-secrets-safer","title":"\u2705 Best Practices That Make Secrets Safer","text":"<p>Recommended Practices</p> <ul> <li>Do NOT hard-code credentials inside container images or Pod specs</li> <li>Do NOT commit Secret YAML files with real values to Git</li> <li>Enable Encryption at Rest for Secrets in etcd</li> <li>Apply RBAC to strictly control Secret access</li> <li>Limit who can run <code>kubectl get secret -o yaml</code></li> <li>Use separate namespaces and least-privilege access</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#how-kubernetes-handles-secrets-securely-at-runtime","title":"\u2699\ufe0f How Kubernetes Handles Secrets Securely at Runtime","text":"<p>Built-in Runtime Protections</p> <ul> <li>Secrets are sent to a node only if a Pod on that node needs them</li> <li>kubelet stores Secrets in tmpfs (memory) \u2014 not written to disk</li> <li>Secret data is not persisted to node storage</li> <li>When the dependent Pod is deleted \u2192 kubelet removes the Secret copy</li> <li>Secrets are not automatically shared across Pods</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#what-secrets-do-not-protect-you-from","title":"\u26a0\ufe0f What Secrets Do NOT Protect You From","text":"<p>Know the Limits</p> <ul> <li>Base64 encoding is reversible</li> <li>Anyone with etcd access can read Secrets (unless encryption at rest is enabled)</li> <li>Cluster-admin users can read all Secrets</li> <li>etcd backups contain Secret data</li> <li>Secret manifests with values are risky in Git repos</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#better-production-grade-secret-solutions","title":"\ud83c\udfed Better Production-Grade Secret Solutions","text":"<p>Stronger Options for Sensitive Data</p> <p>Use external or encrypted secret systems for high-security environments:</p> <ul> <li>HashiCorp Vault</li> <li>Cloud Secret Managers (AWS / GCP / Azure)</li> <li>Kubernetes Secrets Store CSI Driver</li> <li>Helm Secrets plugin</li> <li>Mozilla SOPS + GitOps workflows</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#production-best-practices","title":"\ud83c\udfed Production Best Practices","text":"<p>Success</p> <p>Use KMS v2 when available</p> <p>Success</p> <p>Rotate keys regularly</p> <p>Success</p> <p>Restrict etcd access</p> <p>Success</p> <p>Enable etcd TLS</p> <p>Success</p> <p>Protect encryption config file</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#donts","title":"\u274c Don\u2019ts","text":"<p>Danger</p> <p>Do not leave identity first</p> <p>Danger</p> <p>Do not store keys in Git</p> <p>Danger</p> <p>Do not skip rotation</p> <p>Danger</p> <p>Do not expose etcd</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.04%20Encrypting%20Secret%20Data%20at%20Rest/#quick-summary","title":"\u2705 Quick Summary","text":"<p>Summary</p> <ul> <li>Secrets are not encrypted by default</li> <li>Enable encryption-provider-config</li> <li>Encrypt secrets resource</li> <li>Provider order matters</li> <li>Verify via etcdctl</li> <li>Rewrite old secrets</li> <li>Use KMS in production</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/","title":"4.05 Multi Container Pods","text":"<ul> <li> <p>Multi-container Pods allow multiple containers to run inside a single Kubernetes Pod when they must be tightly coupled and operate together.</p> </li> <li> <p>Instead of merging everything into one large container image, Kubernetes lets you package helper components alongside the main application container.</p> </li> </ul> Typical real-world examples: <pre><code>  1. App + reverse proxy\n  2. App + log shipper\n  3. App + metrics exporter\n  4. App + config reloader\n  5. App + dependency checker\n  6. App + service mesh proxy\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#what-makes-multi-container-pods-special","title":"\ud83c\udfaf What Makes Multi-Container Pods Special","text":"<p>Containers inside the same Pod share:</p> <ul> <li>\u2705 Lifecycle (start and stop together)</li> <li>\u2705 Network namespace (same IP, use <code>localhost</code>)</li> <li>\u2705 Storage volumes</li> <li>\u2705 Scheduling &amp; node placement</li> <li>\u2705 Restart behavior</li> </ul> <p>Success</p> <p>Multi-container Pods are meant for tightly coupled helper containers, not unrelated services.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#when-you-should-use-multi-container-pods","title":"\ud83e\udde0 When You SHOULD Use Multi-Container Pods","text":"<p>Use multi-container Pods when containers must:</p> <ul> <li>Always run together</li> <li>Scale together</li> <li>Share files directly</li> <li>Communicate via localhost</li> <li>Be deployed as one unit</li> </ul> <p>Warning</p> <p>If components can scale independently \u2192 use separate Deployments, not one Pod.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#basic-multi-container-pod-example","title":"\ud83e\uddf1 Basic Multi-Container Pod Example","text":"<p>The <code>containers</code> field is a list \u2014 this allows multiple containers in one Pod.</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: simple-webapp\nspec:\n  containers:\n    - name: web-app\n      image: web-app\n      ports:\n        - containerPort: 8080\n\n    - name: main-app\n      image: main-app\n</code></pre> <p>Behavior:</p> <ul> <li>Both containers start together</li> <li>Both run together</li> <li>Both stop together</li> <li>No startup order guarantee</li> </ul> <p>Note</p> <p>Kubernetes does not guarantee which container starts first in this pattern.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#multi-container-pod-design-patterns","title":"\ud83e\udde9 Multi-Container Pod Design Patterns","text":"<p>There are three core patterns you must know:</p> <ol> <li>Co\u2011Located Containers</li> <li>Init Containers</li> <li>Sidecar Containers</li> </ol>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#1-colocated-containers-pattern","title":"1\ufe0f\u20e3 Co\u2011Located Containers Pattern","text":"<p>Two or more containers:</p> <ul> <li>Run for full Pod lifecycle</li> <li>No guaranteed startup order</li> <li>All are long-running</li> </ul> <p>Use when:</p> <ul> <li>Containers depend on each other</li> <li>No strict startup sequencing required</li> </ul> <pre><code>spec:\n  containers:\n    - name: app\n      image: app-image\n\n    - name: helper\n      image: helper-image\n</code></pre> <p>Note</p> <p>Good for helper daemons, lightweight proxies, or tightly bound services.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#2-init-containers-pattern","title":"2\ufe0f\u20e3 Init Containers Pattern","text":"<p>Init containers run before main containers start.</p> <p>Rules:</p> <ul> <li>Must complete successfully</li> <li>Run sequentially</li> <li>Main containers wait until init completes</li> </ul> <p>Used for:</p> <ul> <li>Database readiness checks</li> <li>Schema migrations</li> <li>Config downloads</li> <li>Dependency validation</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#init-container-db-readiness-template","title":"\ud83d\udee0 Init Container \u2014 DB Readiness Template","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: app-pod\nspec:\n  initContainers:\n    - name: db-wait\n      image: busybox\n      command:\n        - sh\n        - -c\n        - &gt;\n          until nc -z db-service 5432;\n          do echo \"Waiting for DB...\";\n          sleep 2;\n          done\n\n  containers:\n    - name: app\n      image: my-app\n</code></pre> <p>Tip</p> <p>Prefer init containers over sleep loops inside your main app.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#multiple-init-containers-ordered-execution","title":"\ud83d\udd04 Multiple Init Containers \u2014 Ordered Execution","text":"<p>Init containers run one-by-one in order:</p> <pre><code>initContainers:\n  - name: db-checker\n    image: busybox\n    command: [\"sh\",\"-c\",\"./wait-for-db.sh\"]\n\n  - name: api-checker\n    image: busybox\n    command: [\"sh\",\"-c\",\"./wait-for-api.sh\"]\n</code></pre> <p>Execution order:</p> <pre><code>db-checker \u2192 api-checker \u2192 main container\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#3-sidecar-containers-pattern","title":"3\ufe0f\u20e3 Sidecar Containers Pattern","text":"<p>Sidecar containers:</p> <ul> <li>Run alongside main container</li> <li>Support main container</li> <li>Run for full Pod lifecycle</li> <li>Provide helper capabilities</li> </ul> <p>Used for:</p> <ul> <li>Log shipping</li> <li>Metrics exporting</li> <li>Security monitoring</li> <li>Config reloaders</li> <li>Service mesh proxies</li> </ul> <p>Success</p> <p>Sidecars extend app behavior without modifying app code.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#sidecar-pattern-logging-example","title":"\ud83e\uddf1 Sidecar Pattern \u2014 Logging Example","text":"<p>A common production use case:</p> <p>App + Log Shipper Sidecar</p> <p>Flow:</p> <pre><code>App \u2192 writes logs \u2192 shared volume \u2192 sidecar ships logs \u2192 Elasticsearch \u2192 Kibana\n</code></pre> <p>This ensures:</p> <ul> <li>Startup logs captured</li> <li>Runtime logs streamed</li> <li>Crash/termination logs preserved</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#sidecar-pattern-yaml","title":"\u2699\ufe0f Sidecar Pattern YAML","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: simple-webapp\n  labels:\n    name: simple-webapp\nspec:\n  containers:\n    - name: web-app\n      image: web-app\n      ports:\n        - containerPort: 8080\n\n  initContainers:\n    - name: log-shipper\n      image: busybox\n      command: 'setup-log-shipper.sh'\n      restartPolicy: Always\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#about-restartpolicy","title":"\ud83d\udd01 About restartPolicy","text":"<ul> <li> <p><code>restartPolicy</code>  set to always for Sidecar Pattern in Init Containers. So this will also ensure the init container is terminated after the main application stops.</p> </li> <li> <p>That way the log shipper can catch the startup and termination logs of the main container.</p> </li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#valid-restartpolicy-values","title":"Valid restartPolicy values:","text":"<ul> <li>Always </li> <li>OnFailure</li> <li>Never</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#sidecar-vs-init-container-difference","title":"\ud83e\udde0 Sidecar vs Init Container \u2014 Difference","text":"Feature Init Container Sidecar Container Runs before app \u2705 \u2705 Stops before app starts \u2705 \u274c Runs during app lifecycle \u274c \u2705 Used for Setup / checks Continuous support <p>Note</p> <p>Init containers execute setup tasks and terminate, while sidecars provide continuous support services and run as long as the Pod is running.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#production-use-cases","title":"\ud83d\ude80 Production Use Cases","text":"<ul> <li>Log shippers (Fluent Bit, Filebeat)</li> <li>Metrics exporters</li> <li>Security agents</li> <li>Service mesh proxies (Envoy)</li> <li>Config reload helpers</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#troubleshooting-multi-container-pods","title":"\ud83e\uddea Troubleshooting Multi-Container Pods","text":"<p>Always debug per-container.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#describe-pod","title":"Describe Pod","text":"<pre><code>kubectl describe pod &lt;pod&gt;\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#logs-per-container","title":"Logs per container","text":"<pre><code>kubectl logs &lt;pod&gt; -c app\nkubectl logs &lt;pod&gt; -c sidecar\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#exec-into-specific-container","title":"Exec into specific container","text":"<pre><code>kubectl -n elastic-stack exec -it app -- cat /log/app.log \n# Pod Name: app\n# Command to execute: cat /log/app.log\n</code></pre> <p>Tip</p> <p>Most \u201cPod failures\u201d are actually one container failing.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#production-best-practices","title":"\ud83c\udfed Production Best Practices","text":"<p>Success</p> <p>Keep each container single-purpose</p> <p>Success</p> <p>Use init containers for readiness logic</p> <p>Success</p> <p>Use sidecars for logging &amp; metrics</p> <p>Success</p> <p>Define resource limits per container</p> <p>Success</p> <p>Add readiness &amp; liveness probes</p> <p>Success</p> <p>Use shared volumes carefully</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.05%20Multi%20Container%20Pods/#production-donts","title":"\u274c Production Don\u2019ts","text":"<p>Danger</p> <p>Do not group unrelated services</p> <p>Danger</p> <p>Do not assume container start order</p> <p>Danger</p> <p>Do not put business logic in sidecars</p> <p>Danger</p> <p>Do not skip health probes</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/","title":"4.06 Autoscaling","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#what-is-kubernetes-autoscaling","title":"What is Kubernetes AutoScaling?","text":"<p>Kubernetes AutoScaling automatically adjusts capacity based on traffic and resource usage so your applications stay:</p> <ul> <li>Available under load</li> <li>Cost\u2011efficient during low usage</li> <li>Stable in production</li> </ul> <p>Autoscaling works at two layers:</p> <ul> <li>Cluster Infrastructure \u2192 Nodes (VMs / servers)</li> <li>Workloads \u2192 Pods (application instances)</li> </ul> <p>Two scaling directions:</p> <ul> <li>Horizontal scaling \u2192 Add or remove instances</li> <li>Vertical scaling \u2192 Increase or decrease resources per instance</li> </ul> <p>Success</p> <p>In production, horizontal scaling is preferred first for availability and fault tolerance. Vertical scaling is mainly used for tuning.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#scaling-types-simple-view","title":"Scaling Types \u2014 Simple View","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#cluster-infrastructure-scaling","title":"Cluster Infrastructure Scaling","text":"Type What Changes Example Horizontal Number of nodes Add worker nodes Vertical Node size Increase VM CPU/RAM"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#workload-scaling","title":"Workload Scaling","text":"Type What Changes Example Horizontal Number of pods Increase replicas Vertical Pod resources Increase CPU/memory limits"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#scaling-basics-prekubernetes-concept","title":"Scaling Basics (Pre\u2011Kubernetes Concept)","text":"<p>Core Concept</p> <p>Vertical scaling - Increase CPU/RAM on same server - Usually requires restart - Has an upper limit</p> <p>Horizontal scaling - Add more servers - Share load - Better resilience</p> <p>Kubernetes applies the same ideas to pods and nodes.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#manual-vs-automated-scaling","title":"Manual vs Automated Scaling","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#manual-scaling","title":"Manual Scaling","text":"<p>Manual Commands</p> <pre><code>kubeadm join ...\nkubectl scale deployment app --replicas=5\nkubectl edit deployment app\n</code></pre> <p>Warning</p> <p>Manual scaling is acceptable for testing \u2014 not safe for production spikes.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#autoscaling-components-overview","title":"Autoscaling Components Overview","text":"<p>Kubernetes autoscaling uses:</p> <ul> <li>HPA \u2192 Scale pod count</li> <li>VPA \u2192 Scale pod resources</li> <li>Cluster Autoscaler \u2192 Scale nodes</li> <li>In\u2011Place Resize \u2192 Resize pod resources without recreation (feature\u2011gated)</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#metrics-requirement-critical-for-autoscaling","title":"Metrics Requirement (Critical for Autoscaling)","text":"<p>Required</p> <ul> <li>Metrics Server installed</li> <li>CPU &amp; memory requests defined</li> <li>Limits recommended</li> </ul> <pre><code>kubectl top pods\n</code></pre> <p>Failure</p> <p>Without resource requests \u2192 autoscalers cannot compute utilization.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#horizontal-pod-autoscaler-hpa","title":"Horizontal Pod Autoscaler (HPA)","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#what-hpa-does","title":"What HPA Does","text":"<p>HPA automatically scales number of pods based on metrics.</p> <ul> <li>Reads metrics continuously</li> <li>Compares with target</li> <li>Adds/removes pods</li> </ul> <p>Success</p> <p>Most used autoscaler for stateless production workloads.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#how-hpa-works","title":"How HPA Works","text":"<p>Abstract</p> <p>Traffic \u2191 \u2192 CPU \u2191 \u2192 Metrics Server \u2192 HPA \u2192 More replicas \u2192 Load spreads \u2192 CPU \u2193 \u2192 Scale down</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#supported-metrics","title":"Supported Metrics","text":"<ul> <li>CPU</li> <li>Memory</li> <li>Custom metrics</li> <li>External metrics</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#hpa-requirements","title":"HPA Requirements","text":"<p>Note</p> <ul> <li>Metrics Server</li> <li>Resource requests set</li> <li>Deployment / RS / StatefulSet target</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#hpa-creation","title":"HPA Creation","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#imperative","title":"Imperative","text":"<p>Example</p> <pre><code>kubectl autoscale deployment myapp --cpu-percent=50 --min=2 --max=10\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#declarative","title":"Declarative","text":"<p>Example</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: myapp-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  minReplicas: 2\n  maxReplicas: 12\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 60\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#hpa-best-practices","title":"HPA Best Practices","text":"<p>Success</p> <ul> <li>minReplicas &gt; 1</li> <li>Set safe maxReplicas</li> <li>Use readiness probes</li> <li>Load test thresholds</li> <li>Prefer autoscaling/v2</li> <li>Combine with Cluster Autoscaler</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#dont","title":"\u274c Don\u2019t","text":"<p>Danger</p> <ul> <li>Run without requests</li> <li>Leave max unlimited</li> <li>Use for databases blindly</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#vertical-pod-autoscaler-vpa","title":"Vertical Pod Autoscaler (VPA)","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#what-vpa-does","title":"What VPA Does","text":"<p>VPA automatically adjusts CPU and memory requests/limits of pods based on usage history.</p> <p>Abstract</p> <p>HPA = more pods VPA = bigger pods</p> <p>Note</p> <p>VPA is not built\u2011in \u2014 must be installed.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#why-vpa","title":"Why VPA","text":"<p>Manual vertical scaling requires:</p> <p>Example</p> <pre><code>kubectl top pod\nkubectl edit deployment\n</code></pre> <p>Which causes:</p> <p>Danger</p> <ul> <li>Manual monitoring</li> <li>Pod restart</li> <li>Operational risk</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#vpa-components","title":"VPA Components","text":"<p>Note</p> <p>Recommender - Analyzes historical + live metrics - Suggests CPU/memory</p> <p>Updater - Finds mis-sized pods - Evicts when needed</p> <p>Admission Controller - Injects recommended resources at pod creation</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#install-vpa","title":"Install VPA","text":"<p>Install Controllers</p> <pre><code>kubectl apply -f     https://github.com/kubernetes/autoscaler/releases/latest/download/vertical-pod-autoscaler.yaml\n</code></pre> <p>Verify:</p> <pre><code>kubectl get pods -n kube-system | grep vpa\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#vpa-modes","title":"VPA Modes","text":"<p>VPA behavior depends on update mode.</p> <p>Update Modes</p> <p>Off - Only recommendations - No pod changes</p> <p>Initial - Apply only at pod creation - No evictions</p> <p>Recreate - Evict pods to apply changes - Causes restart</p> <p>Auto - Currently behaves like Recreate - Future: will prefer in-place resize</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#vpa-example","title":"VPA Example","text":"<p>VPA Resource</p> <pre><code>apiVersion: autoscaling.k8s.io/v1\nkind: VerticalPodAutoscaler\nmetadata:\n  name: myapp-vpa\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  updatePolicy:\n    updateMode: Auto\n  resourcePolicy:\n    containerPolicies:\n    - containerName: myapp\n      minAllowed:\n        cpu: 250m\n      maxAllowed:\n        cpu: \"2\"\n</code></pre> <p>Check recommendations:</p> <pre><code>kubectl describe vpa myapp-vpa\n</code></pre>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#vpa-vs-hpa-quick-production-difference","title":"VPA vs HPA \u2014 Quick Production Difference","text":"<p>Abstract</p> <p>VPA \u2192 Changes pod size \u2192 May restart pods HPA \u2192 Changes pod count \u2192 No restarts</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#when-to-use-vpa","title":"When to Use VPA","text":"<p>Tip</p> <ul> <li>Databases</li> <li>JVM apps</li> <li>ML jobs</li> <li>Stateful workloads</li> <li>Resource tuning</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#dont-use-vpa-for","title":"\u274c Don\u2019t Use VPA For","text":"<p>Warning</p> <ul> <li>Traffic spikes</li> <li>Latency\u2011critical APIs</li> <li>Non\u2011restartable apps</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#vpa-best-practices","title":"VPA Best Practices","text":"<p>Success</p> <ul> <li>Start Off mode first</li> <li>Review recommendations</li> <li>Set min/max bounds</li> <li>Use PDB</li> <li>Monitor evictions</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#inplace-pod-resize","title":"In\u2011Place Pod Resize","text":""},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#what-it-is","title":"What It Is","text":"<p>Allows CPU/memory changes without recreating pod.</p> <p>Default behavior:</p> <ul> <li>Resource change \u2192 Pod deleted \u2192 New pod created</li> </ul> <p>With feature:</p> <ul> <li>Resource change \u2192 Pod resized \u2192 Less disruption</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#feature-gate-requirement","title":"Feature Gate Requirement","text":"<p>In-place resize requires enabling the feature gate on control plane and kubelet.</p> <p>Feature Gate Required</p> <p>Enable:</p> <pre><code>FEATURE_GATES=InPlacePodVerticalScaling=true\n</code></pre> <p>If not enabled \u2192 Kubernetes falls back to delete &amp; recreate pod behavior.</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#resize-policy-per-resource","title":"Resize Policy (Per Resource)","text":"<p>You can define resize behavior per resource type.</p> <p>Resize Policy Example</p> <pre><code>resources:\n  requests:\n    cpu: \"1\"\n    memory: \"256Mi\"\n  limits:\n    cpu: \"500m\"\n    memory: \"512Mi\"\n\nresizePolicy:\n- resourceName: cpu\n  restartPolicy: NotRequired\n- resourceName: memory\n  restartPolicy: RestartContainer\n</code></pre> <p>Meaning:</p> <ul> <li>CPU change \u2192 no restart required</li> <li>Memory change \u2192 container restart required</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#limitations","title":"Limitations","text":"<p>Warning</p> <ul> <li>CPU &amp; memory only</li> <li>QoS cannot change</li> <li>No init/ephemeral containers</li> <li>Cannot reduce memory below usage</li> <li>No Windows support</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#inplace-resize-best-practices","title":"In\u2011Place Resize Best Practices","text":"<p>Success</p> <ul> <li>Test first</li> <li>Define resizePolicy</li> <li>Monitor status</li> <li>Use readiness probes</li> </ul>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.06%20Autoscaling/#production-rules-hpa-vs-vpa","title":"Production Rules \u2014 HPA vs VPA","text":"<p>Abstract</p> <p>HPA \u2192 Handle spikes VPA \u2192 Tune resources</p> <p>Quote</p> <p>Use HPA for demand scaling Use VPA for right\u2011sizing Use In\u2011Place Resize to reduce disruption</p>"},{"location":"%E2%98%B8%EF%B8%8F%20Kubernetes/4.Application-Lifecycle-Management/4.10%20Practice-links/","title":"4.10 Practice links","text":"<p>Credits</p> <p>The following practice tests are provided by KodeKloud Labs and are part of the Certified Kubernetes Administrator course by Mumshad Mannambeth on Udemy.</p> <ul> <li> <p>Rolling Updates and Rollbacks</p> </li> <li> <p>Commands and Arguments</p> </li> <li> <p>Env Variables</p> </li> <li> <p>Secrets</p> </li> <li> <p>Multi Container Pods</p> </li> <li> <p>Init Containers</p> </li> <li> <p>Manual Scaling</p> </li> <li> <p>HPA</p> </li> <li> <p>Install VPA</p> </li> <li> <p>Modifying CPU resources in VPA</p> </li> </ul>"},{"location":"%E2%9A%99%EF%B8%8F%20CI-CD/","title":"Index","text":"Github-Actions    <p>use unseen to remove the gif background</p> <p>For full documentation visit mkdocs.org.</p>"},{"location":"%E2%9A%99%EF%B8%8F%20CI-CD/#commands","title":"Commands","text":"<p><code>python3 -m venv venv</code> <code>source venv/bin/active</code> - start venv</p> <ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"%E2%9A%99%EF%B8%8F%20CI-CD/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre> create_folder.sh<pre><code>mkdir k8s-manifests \n</code></pre> main.py<pre><code>def main(){}\n</code></pre> <p>Note</p> <p>hi</p> <p>Abstract</p> <p>hi</p> <p>Info</p> <p>hi</p> <p>Tip</p> <p>hi</p> <p>Success</p> <p>hi</p> <p>Question</p> <p>hi</p> <p>Warning</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Danger</p> <p>hi</p> <p>Bug</p> <p>hi</p> <p>Example</p> <p>hi</p> <p>Quote</p> <p>hi</p>"},{"location":"%F0%9F%8C%90%20Networking/","title":"Index","text":"Networking    <p>use unseen to remove the gif background</p>"},{"location":"%F0%9F%8C%90%20Networking/#commands","title":"Commands","text":"<p><code>python3 -m venv venv</code> <code>source venv/bin/active</code> - start venv</p> <ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"%F0%9F%8C%90%20Networking/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre> create_folder.sh<pre><code>mkdir k8s-manifests \n</code></pre> main.py<pre><code>def main(){}\n</code></pre> <p>Note</p> <p>hi</p> <p>Abstract</p> <p>hi</p> <p>Info</p> <p>hi</p> <p>Tip</p> <p>hi</p> <p>Success</p> <p>hi</p> <p>Question</p> <p>hi</p> <p>Warning</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Danger</p> <p>hi</p> <p>Bug</p> <p>hi</p> <p>Example</p> <p>hi</p> <p>Quote</p> <p>hi</p>"},{"location":"%F0%9F%8F%97%EF%B8%8F%20Terraform/","title":"Index","text":""},{"location":"%F0%9F%8F%97%EF%B8%8F%20Terraform/#commands","title":"Commands","text":"<p><code>python3 -m venv venv</code> <code>source venv/bin/active</code> - start venv</p> <ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"%F0%9F%8F%97%EF%B8%8F%20Terraform/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre> create_folder.sh<pre><code>mkdir k8s-manifests \n</code></pre> main.py<pre><code>def main(){}\n</code></pre> <p>Note</p> <p>hi</p> <p>Abstract</p> <p>hi</p> <p>Info</p> <p>hi</p> <p>Tip</p> <p>hi</p> <p>Success</p> <p>hi</p> <p>Question</p> <p>hi</p> <p>Warning</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Danger</p> <p>hi</p> <p>Bug</p> <p>hi</p> <p>Example</p> <p>hi</p> <p>Quote</p> <p>hi</p>"},{"location":"%F0%9F%90%8D%20Python%2Bscripting/","title":"Index","text":""},{"location":"%F0%9F%90%8D%20Python%2Bscripting/#commands","title":"Commands","text":"<p><code>python3 -m venv venv</code> <code>source venv/bin/active</code> - start venv</p> <ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"%F0%9F%90%8D%20Python%2Bscripting/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre> create_folder.sh<pre><code>mkdir k8s-manifests \n</code></pre> main.py<pre><code>def main(){}\n</code></pre> <p>Note</p> <p>hi</p> <p>Abstract</p> <p>hi</p> <p>Info</p> <p>hi</p> <p>Tip</p> <p>hi</p> <p>Success</p> <p>hi</p> <p>Question</p> <p>hi</p> <p>Warning</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Danger</p> <p>hi</p> <p>Bug</p> <p>hi</p> <p>Example</p> <p>hi</p> <p>Quote</p> <p>hi</p>"},{"location":"%F0%9F%90%A7%20Linux%2BScripting/","title":"Index","text":"Linux"},{"location":"%F0%9F%90%A7%20Linux%2BScripting/#commands","title":"Commands","text":"<p><code>python3 -m venv venv</code> <code>source venv/bin/active</code> - start venv</p> <ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"%F0%9F%90%A7%20Linux%2BScripting/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre> create_folder.sh<pre><code>mkdir k8s-manifests \n</code></pre> main.py<pre><code>def main(){}\n</code></pre> <p>Note</p> <p>hi</p> <p>Abstract</p> <p>hi</p> <p>Info</p> <p>hi</p> <p>Tip</p> <p>hi</p> <p>Success</p> <p>hi</p> <p>Question</p> <p>hi</p> <p>Warning</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Danger</p> <p>hi</p> <p>Bug</p> <p>hi</p> <p>Example</p> <p>hi</p> <p>Quote</p> <p>hi</p>"},{"location":"%F0%9F%90%B3%20Docker/","title":"Index","text":""},{"location":"%F0%9F%90%B3%20Docker/#commands","title":"Commands","text":"<p><code>python3 -m venv venv</code> <code>source venv/bin/active</code> - start venv</p> <ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"%F0%9F%90%B3%20Docker/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre> create_folder.sh<pre><code>mkdir k8s-manifests \n</code></pre> main.py<pre><code>def main(){}\n</code></pre> <p>Note</p> <p>hi</p> <p>Abstract</p> <p>hi</p> <p>Info</p> <p>hi</p> <p>Tip</p> <p>hi</p> <p>Success</p> <p>hi</p> <p>Question</p> <p>hi</p> <p>Warning</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Danger</p> <p>hi</p> <p>Bug</p> <p>hi</p> <p>Example</p> <p>hi</p> <p>Quote</p> <p>hi</p>"},{"location":"%F0%9F%93%8A%20Monitoring%20%26%20logging/","title":"Index","text":"Monitoring and Logging    <p>use unseen to remove the gif background</p>"},{"location":"%F0%9F%93%8A%20Monitoring%20%26%20logging/#commands","title":"Commands","text":"<p><code>python3 -m venv venv</code> <code>source venv/bin/active</code> - start venv</p> <ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"%F0%9F%93%8A%20Monitoring%20%26%20logging/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre> create_folder.sh<pre><code>mkdir k8s-manifests \n</code></pre> main.py<pre><code>def main(){}\n</code></pre> <p>Note</p> <p>hi</p> <p>Abstract</p> <p>hi</p> <p>Info</p> <p>hi</p> <p>Tip</p> <p>hi</p> <p>Success</p> <p>hi</p> <p>Question</p> <p>hi</p> <p>Warning</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Danger</p> <p>hi</p> <p>Bug</p> <p>hi</p> <p>Example</p> <p>hi</p> <p>Quote</p> <p>hi</p>"},{"location":"%F0%9F%94%80%20Git/","title":"Index","text":"<p>use unseen to remove the gif background</p>"},{"location":"%F0%9F%94%80%20Git/#commands","title":"Commands","text":"<p><code>python3 -m venv venv</code> <code>source venv/bin/active</code> <code>mkdocs serve --clean</code> <code>mkdocs serve --dev-addr 127.0.0.1:8085</code> - start venv</p> <ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"%F0%9F%94%80%20Git/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre> create_folder.sh<pre><code>mkdir k8s-manifests \n</code></pre> main.py<pre><code>def main(){}\n</code></pre> <p>Note</p> <p>hi</p> <p>Abstract</p> <p>hi</p> <p>Info</p> <p>hi</p> <p>Tip</p> <p>hi</p> <p>Success</p> <p>hi</p> <p>Question</p> <p>hi</p> <p>Warning</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Failure</p> <p>hi</p> <p>Danger</p> <p>hi</p> <p>Bug</p> <p>hi</p> <p>Example</p> <p>hi</p> <p>Quote</p> <p>hi</p>"}]}